################################################################################
#
# This file defines the grammar for SQL statements of various types. The
# first section (Table names and Column names) is specific to the DDL table
# definitions that are used, along with this file, to test VoltDB; but most of
# the rest (with certain exceptions, like table and column aliases, and polygon
# values) is (intended to be) completely general, albeit it will need to be
# added to whenever new SQL functions or other features are added to VoltDB.
#
# The parser that interprets this file understands only a few simple rules:
#   1. The ::= symbol means "is defined as". Definitions are normally given on
#      a single line, but may be continued onto one or more additional lines
#      using a backslash (\) as a continuation character; the backslash must
#      be the last character on the line.
#   2. The {foo} syntax means to use symbol "foo", which is defined somewhere
#      in this file, using "::="; recursive definitions are allowed, though of
#      course a non-recursive option must also be available, to avoid infinite
#      recursion.
#   3. The | symbol means "or" (actually, XOR), with an equal probability of
#      each possible option being chosen, by default (but see #4 below). The |
#      must be preceded and followed by a space (otherwise the || concatenation
#      operator would be impossible without some sort of escape symbol, which
#      I did not want to get into).
#   4. Adding an integer before a | symbol makes the preceding option more
#      likely; the "n|" still needs to be preceded and followed by a space.
#      For example, in this definition:
#          {definition} :== foo 2| bar
#      the "foo" option is twice as likely as the "bar" option. You may use
#      more than one such integer; for example, in this definition:
#          {definition} :== foo 3| bar 2| null
#      the "foo" option will be chosen half (3/6) the time, the "bar" option
#      will be chosen a third (2/6) of the time, and the "null" option will
#      be chosen only 1 time in 6. Note that the last option always has an
#      implicit "likelihood weight" of 1, as do any options preceded simply with
#      a |. The actual probability of each option is its "likelihood weight"
#      divided by the sum of all the "likelihood weights" of all options.
#   5. Something in brackets, such as [foo], is optional, with a 50-50 chance
#      of being included; If you want to make something optional less likely,
#      add more brackets, e.g., [[foo]] has only a 25% chance of being included.
#   6. You cannot include | inside brackets, so [foo | bar] will not work
#      properly, though the reverse, e.g. [foo] | [bar] is fine; to achieve
#      the same effect as [foo | bar] use [foo-or-bar], with:
#          {foo-or-bar} :== foo | bar
#      See "all-or-distinct" for one example of this.
#
################################################################################

################################################################################
# Table and view names pre-defined in the DDL associated with this test
# (and very occasionally, a nonexistent table name, view name, or, below,
# column name is used)
legit-table-name        ::= R0 | P0 | R1 | P1 | R2 | P2 | R3 | P3 | R4 | P4 | \
                            R5 | P5 | R6 | P6 | R7 | P7
legit-view-name         ::= VR1 | VP1 | VR2 | VP2 | VR3 | VP3 | VR4 | VP4 | VR5 | VP5
table-name              ::= {legit-table-name} 199| NONEXISTENT_TABLE
view-name               ::= {legit-view-name}  199| NONEXISTENT_VIEW

# TODO: also pre-define some Stored Procedures

# Column names used in the pre-defined DDL, of every possible data type ...
int-column-name         ::= ID | TINY | SMALL | INT | BIG
byte-column-name        ::= TINY

# The "5" before the "|" makes the "int-column-name" option 5 times as likely
# as the other options, making each numeric column name equally likely
numeric-column-name     ::= {int-column-name} 5| NUM | DEC

string-column-name      ::= VCHAR_INLINE | VCHAR_INLINE_MAX | VCHAR | VCHAR_JSON
timestamp-column-name   ::= TIME
varbinary-column-name   ::= VARBIN
point-column-name       ::= POINT
polygon-column-name     ::= POLYGON
geo-column-name         ::= {point-column-name} | {polygon-column-name}
non-int-str-column-name ::= {geo-column-name} 2| {timestamp-column-name} | {varbinary-column-name}

# PostgreSQL-compatible version of the above: avoids problems involving SELECT with Geospatial types
pg-point-column-name    ::= _variable\[point\]
pg-polygon-column-name  ::= _variable\[polygon\]

table-column-name       ::= {numeric-column-name} 2| {string-column-name} | {non-int-str-column-name}
view-column-name        ::= {table-column-name}
legit-column-name       ::= {table-column-name} 9| {view-column-name}
column-name             ::= {legit-column-name} 399| NONEXISTENT_COLUMN
column-list             ::= {column-name} [, {column-list}]

# These are obviously not the complete lists of all possible table and column
# aliases, but using a short list makes it more likely that when you refer to
# one it is one that was actually defined
table-alias             ::= T1 3| T2 2| T3
column-alias            ::= C1 3| C2 2| C3

################################################################################
# Any (non-DDL) SQL statement:
# The "50" before the first "|" makes the "select-statement" option 50 times as
# likely as the least likely (last) option; so half of these SQL statements will
# be SELECT statements; but only 1% will be "delete-statement", since we don't
# want to delete all the rows in a table too often.
#
sql-statement           ::= {select-statement} 50| {insert-statement} 20| {upsert-statement} 20| \
                            {update-statement}  9| {delete-statement}

################################################################################
# Grammar rules for an INSERT statement:
################################################################################
insert-statement        ::= {insert-values-statement} | {insert-select-statement}

# The "9" before the "|" makes the "simple-insert-values" or "ordered-values-list"
# option 9 times as likely as the other option, making simple, ordered, valid
# statements more likely
insert-values-statement ::= {simple-insert-values} 9| {insert-clause} VALUES ({values-list})
insert-select-statement ::= {simple-insert-select} 9| {insert-clause} {select-statement}
values-list             ::= {ordered-values-list}  9| {random-order-value-list}

# Putting "({column-list})" in more than one set of brackets makes it less likely
insert-clause           ::= INSERT INTO {table-name} [[({column-list})]]

ordered-values-list     ::= {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value}, {integer-value}, \
                            {numeric-value}, {numeric-value}, {string-value}, {string-value}, {string-value}, \
                            {timestamp-value}, {varbinary-value}, {point-value}, {polygon-value}
random-order-value-list ::= {random-type-value} [, {random-order-value-list}]
random-type-value       ::= {integer-value}  4| {numeric-value} 2| {string-value} 4| {timestamp-value} | \
                            {varbinary-value} | {point-value}    | {polygon-value}
simple-insert-values    ::= IN{in-or-up-sert-values}
simple-insert-select    ::= IN{in-or-up-sert-select}

in-or-up-sert-values    ::= {insert-values-multiple} 8| {insert-values-all}    22| {insert-values-backward} 22| \
                            {insert-values-id-num}   7| {insert-values-id-str}  4| {insert-values-id-time}    | \
                            {insert-values-id-varbin} | {insert-values-id-point} | {insert-values-id-poly}
in-or-up-sert-select    ::= {insert-select-multiple} 8| {insert-select-all}    22| {insert-select-backward} 22| \
                            {insert-select-id-num}   7| {insert-select-id-str}  4| {insert-select-id-time}    | \
                            {insert-select-id-varbin} | {insert-select-id-point} | {insert-select-id-poly}

# We leave the IN off of INSERT here, so these can also be used for UPSERT
insert-values-id-num    ::= SERT INTO {table-name} (ID, {numeric-column-name})   VALUES ({integer-non-null-value}, {numeric-value})
insert-values-id-str    ::= SERT INTO {table-name} (ID, {string-column-name})    VALUES ({integer-non-null-value}, {string-value})
insert-values-id-time   ::= SERT INTO {table-name} (ID, {timestamp-column-name}) VALUES ({integer-non-null-value}, {timestamp-value})
insert-values-id-varbin ::= SERT INTO {table-name} (ID, {varbinary-column-name}) VALUES ({integer-non-null-value}, {varbinary-value})
insert-values-id-point  ::= SERT INTO {table-name} (ID, {point-column-name})     VALUES ({integer-non-null-value}, {point-value})
insert-values-id-poly   ::= SERT INTO {table-name} (ID, {polygon-column-name})   VALUES ({integer-non-null-value}, {polygon-value})

insert-values-multiple  ::= SERT INTO {table-name} ( ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                            {varbinary-column-name}, {point-column-name}, {polygon-column-name} ) VALUES ( {integer-non-null-value}, \
                            {numeric-value}, {string-value}, {timestamp-value}, {varbinary-value}, {point-value}, {polygon-value} )
insert-values-all       ::= SERT INTO {table-name} ( \
                            ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, VCHAR_JSON, TIME, VARBIN,  \
                            POINT, POLYGON) VALUES ( {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value},  \
                            {integer-value}, {numeric-value}, {numeric-value}, {string-value}, {string-value}, {string-value},  \
                            {json-value}, {timestamp-value}, {varbinary-value}, {point-value}, {polygon-value} )
insert-values-backward  ::= SERT INTO {table-name} ( \
                            POLYGON, POINT, VARBIN, TIME, VCHAR_JSON, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, DEC, NUM, BIG, INT, \
                            SMALL, TINY, ID ) VALUES ( {polygon-value}, {point-value}, {varbinary-value}, {timestamp-value}, \
                            {json-value}, {string-value}, {string-value}, {string-value}, {numeric-value}, {numeric-value}, \
                            {integer-value}, {integer-value}, {integer-value}, {byte-value}, {integer-non-null-value} )

insert-select-id-num    ::= SERT INTO {table-name} (ID, {numeric-column-name})   SELECT {int-column-name}, {numeric-column-name}   FROM {table-reference}
insert-select-id-str    ::= SERT INTO {table-name} (ID, {string-column-name})    SELECT {int-column-name}, {string-column-name}    FROM {table-reference}
insert-select-id-time   ::= SERT INTO {table-name} (ID, {timestamp-column-name}) SELECT {int-column-name}, {timestamp-column-name} FROM {table-reference}
insert-select-id-varbin ::= SERT INTO {table-name} (ID, {varbinary-column-name}) SELECT {int-column-name}, {varbinary-column-name} FROM {table-reference}
insert-select-id-point  ::= SERT INTO {table-name} (ID, {point-column-name})     SELECT {int-column-name}, {point-column-name}     FROM {table-reference}
insert-select-id-poly   ::= SERT INTO {table-name} (ID, {polygon-column-name})   SELECT {int-column-name}, {polygon-column-name}   FROM {table-reference}

insert-select-multiple  ::= SERT INTO {table-name} ( ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                            {varbinary-column-name}, {point-column-name}, {polygon-column-name} ) SELECT {int-column-name}, \
                            {numeric-column-name}, {string-column-name}, {timestamp-column-name}, {varbinary-column-name}, \
                            {point-column-name}, {polygon-column-name} FROM {table-reference}
insert-select-all       ::= SERT INTO {table-name} ( \
                            ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN, POINT, POLYGON ) SELECT \
                            ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN, POINT, POLYGON FROM {table-reference}
insert-select-backward  ::= SERT INTO {table-name} ( \
                            POLYGON, POINT, VARBIN, TIME, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT, SMALL, TINY, ID ) SELECT \
                            POLYGON, POINT, VARBIN, TIME, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT, SMALL, TINY, ID FROM {table-reference}

################################################################################
# Grammar rules for an UPSERT statement (almost identical to INSERT):
################################################################################
upsert-statement        ::= {upsert-values-statement} | {upsert-select-statement}

# The "9" before the "|" makes the "simple-upsert-values" or "simple-upsert-select"
# option 9 times as likely as the other option, making simple, valid statements
# more likely
upsert-values-statement ::= {simple-upsert-values} 9| {upsert-clause} VALUES ({values-list})
upsert-select-statement ::= {simple-upsert-select} 9| {upsert-clause} {select-statement}

# Putting "({column-list})" in more than one set of brackets makes it less likely
upsert-clause           ::= UPSERT INTO {table-name} [[({column-list})]]

simple-upsert-values    ::= UP{in-or-up-sert-values}
simple-upsert-select    ::= UP{in-or-up-sert-select}

################################################################################
# Grammar rules for an UPDATE statement:
################################################################################
update-statement        ::= UPDATE {table-name} SET {column-updates} [{where-clause}]

column-updates          ::= {column-update} [, {column-updates}]
column-update           ::= {column-name}           = {value-expression}     | \
                            {numeric-column-name}   = {numeric-expression}  7| \
                            {string-column-name}    = {string-expression}   4| \
                            {timestamp-column-name} = {timestamp-expression} | \
                            {varbinary-column-name} = {varbinary-expression} | \
                            {point-column-name}     = {point-expression}     | \
                            {polygon-column-name}   = {polygon-expression}

################################################################################
# Grammar rules for a DELETE (or TRUNCATE) statement:
################################################################################
# The "9" before the "|" makes the "basic-delete-statement" option much more
# likely than the "truncate-statement" option, since we don't want to truncate
# (delete all data from) a table too often
#
delete-statement        ::= {basic-delete-statement} 9| {truncate-statement}

basic-delete-statement  ::= DELETE FROM {table-name} [{where-clause}] [{sort-clause}]

truncate-statement      ::= TRUNCATE TABLE {table-name}

################################################################################
# Grammar rules for a SELECT statement (lots of these!):
################################################################################
select-statement        ::= {basic-select-statement} 9| {select-statement} {set-operator} {select-statement}
set-operator            ::= UNION [ALL] | INTERSECT [ALL] | EXCEPT

# Putting the "top-clause" and "all-or-distinct" in more than one set of
# brackets makes them less likely
basic-select-statement  ::= SELECT {top-all-or-distinct} {select-list} FROM {from-clause}
top-all-or-distinct     ::= [[[{top-clause}]]] [[{all-or-distinct}]]
from-clause             ::= {table-references} [[{join-clause}]] [[{where-clause}]] [[{group-clause}]] [{sort-clause}]
from-clause-no-limit    ::= {table-references} [[{join-clause}]] [[{where-clause}]] [[{group-clause}]] [{order-by-clause}]

all-or-distinct         ::= ALL | DISTINCT
select-list             ::= {select-list-item} [[, {select-list}]]
select-list-item        ::= {star} 5| {column-expression} [[AS] {column-alias}] 14| {window-function-expr} [[AS] {column-alias}]
column-expression       ::= {column-name} 2| {selection-expression}
column-reference        ::= {column-name} 2| {column-alias}
column-ref-or-expr      ::= {column-reference} | {column-expression}

# Putting the ", {table-references}" in more than one set of brackets makes it less likely
table-references        ::= {table-reference} [[, {table-references}]]

# The "3" before the first "|" makes the "table-name..." option, and the "2"
# before the "view-name..." option, makes them more likely than the "sub-query..."
# option, making simple, valid statements more likely
table-reference         ::= {table-name} [[AS] {table-alias}] 3| {view-name} [[AS] {table-alias}] 2| {sub-query} [AS] {table-alias}

# Defining these separately so that they can optionally be overridden, for use
# with SQLCoverage, to avoid syntax (TOP) not supported by PostgreSQL, and
# issues with Geospatial types (point & polygon), where using * can be a problem
top-clause              ::= TOP {non-negative-int-value}
top-one                 ::= TOP 1
star                    ::= *
# PostgreSQL-compatible versions of the above: avoids problems involving SELECT * with Geospatial types;
# and involving TOP, which PostgreSQL does not support
pg-star                 ::= ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, VCHAR_JSON, TIME, VARBIN, AsText(POINT), AsText(POLYGON)
pg-top-clause           ::=
pg-top-one              ::=

where-clause            ::= WHERE {boolean-expression}
boolean-expression      ::=   [NOT ] {boolean-type-expr}   [[{and-or} {boolean-expression}]] 3| \
                            ([[NOT ]]{boolean-expression}) [[{and-or} {boolean-expression}]]
and-or                  ::= AND | OR

# TODO: allow for multi-joins (on more than 2 tables)
join-clause             ::= [{join-type}] JOIN {table-reference} [{join-condition}]
join-type               ::= INNER | {left-or-right} [OUTER]
left-or-right           ::= LEFT | RIGHT | FULL
join-condition          ::= ON {join-expression} | USING ({column-reference})
# TODO: probably should be more specific (e.g. equi-join)
join-expression         ::= {boolean-expression}

group-clause            ::= GROUP BY {group-by-list} [HAVING {boolean-expression}]
order-by-clause         ::= ORDER BY {order-by-list}
sort-clause             ::= [{order-by-clause}] [LIMIT {non-negative-int-value}] [OFFSET {non-negative-int-value}]
group-by-list           ::= {column-ref-or-expr}                 [, {group-by-list}]
order-by-list           ::= {column-ref-or-expr} [{asc-or-desc}] [, {order-by-list}]
asc-or-desc             ::= ASC | DESC

# PostgreSQL-compatible version of the above: avoids LIMIT or OFFSET without ORDER BY
pg-sort-clause          ::= {order-by-clause}, ID [LIMIT {non-negative-int-value}] [OFFSET {non-negative-int-value}]

# TODO: add more expression types, and boolean expression types,
# using different data types (varbinary, point, polygon)
value-expression        ::= {numeric-expression} 7| {string-expression} 4| {timestamp-expression}
selection-expression    ::= {value-expression} 9| COUNT(*)
boolean-type-expr       ::= {column-expression} IS [NOT ]NULL | {sub-query} | \
                            {boolean-numeric-expr} 7| {boolean-string-expr} 4| {boolean-timestamp-expr} | \
                            EXISTS {sub-query}
boolean-numeric-expr    ::= {numeric-expression}   {comparison-operator} {numeric-expression}   4| \
                            {numeric-column-name}   IN {numeric-sub-query}
boolean-string-expr     ::= {string-expression}    {comparison-operator} {string-expression}    4| \
                            {string-column-name}    IN {string-sub-query}
boolean-timestamp-expr  ::= {timestamp-expression} {comparison-operator} {timestamp-expression} 4| \
                            {timestamp-column-name} IN {timestamp-sub-query}
comparison-operator     ::= = | <> | != | < | > | <= | >=

################################################################################
# Sub-queries, scalar and otherwise, of various types
#
sub-query               ::= ({select-statement}) 3| {scalar-sub-query}
scalar-sub-query        ::= {numeric-scalar-sub-q} 7| {string-scalar-sub-q} 4| \
                            {timestamp-scalar-sub-q}

numeric-sub-query       ::= (SELECT {top-all-or-distinct}   {numeric-expression} FROM {from-clause})
string-sub-query        ::= (SELECT {top-all-or-distinct}    {string-expression} FROM {from-clause})
timestamp-sub-query     ::= (SELECT {top-all-or-distinct} {timestamp-expression} FROM {from-clause})
numeric-scalar-sub-q    ::= (SELECT  {aggregate-function}({numeric-expression})  FROM {from-clause}) 3| \
                            (SELECT {num-result-aggr-func}({column-expression})  FROM {from-clause}) 3| \
                            (SELECT COUNT(*)                                     FROM {from-clause})  | \
                            (SELECT {top-one}   {numeric-expression} FROM {from-clause-no-limit})     | \
                            (SELECT             {numeric-expression} FROM {from-clause-no-limit} LIMIT 1)
string-scalar-sub-q     ::= (SELECT {min-or-max-aggr-func}({string-expression})  FROM {from-clause}) 6| \
                            (SELECT {top-one}    {string-expression} FROM {from-clause-no-limit})     | \
                            (SELECT              {string-expression} FROM {from-clause-no-limit} LIMIT 1)
timestamp-scalar-sub-q  ::= (SELECT {min-or-max-aggr-func}({timestamp-expression}) FROM {from-clause}) 6| \
                            (SELECT {top-one} {timestamp-expression} FROM {from-clause-no-limit})       | \
                            (SELECT           {timestamp-expression} FROM {from-clause-no-limit} LIMIT 1)

################################################################################
# Window functions - a.k.a. analytic functions
#
window-function-expr    ::= {window-function} OVER ({partition-or-order-by})
window-function         ::= {window-agg-func-expr} 4| COUNT(*) | RANK() | DENSE_RANK()

# SUM can only take numeric argument; others can take any type;
# (AVG not actually supported here, but it should not crash)
window-agg-func-expr    ::= {non-num-aggregate-func}({column-expression}) 3| \
                            {num-only-aggregate-func}({numeric-expression})

# This is somewhat redundant, but since some window functions (RANK, DENSE_RANK)
# require an ORDER BY, we make that more likely; and while other window functions
# do allow this to be empty, that is less interesting, even when legal, so we
# make it less likely
partition-or-order-by   ::= [PARTITION BY {partition-by-list}]  ORDER BY {window-order-by-list} | \
                            [PARTITION BY {partition-by-list}] [ORDER BY {window-order-by-list}]
partition-by-list       ::= {column-expression} [[, {partition-by-list}]]

# Some window functions (RANK, DENSE_RANK) only allow a single int or timestamp
# expression in the ORDER BY clause, so we make those options more likely
window-order-by-list    ::= {window-order-by-item} [{asc-or-desc}] [[, {window-order-by-list}]]
window-order-by-item    ::= {column-expression} 2| {int-expression} | {timestamp-expression}

################################################################################
# Aggregate functions - used with various data types defined below
# (and in the window functions and scalar sub-queries above)
#
# TODO: More use of these in GROUP BY queries
num-only-aggregate-func ::= SUM | AVG
num-result-aggr-func    ::= COUNT 3| APPROX_COUNT_DISTINCT
min-or-max-aggr-func    ::= MIN | MAX
non-num-aggregate-func  ::= {min-or-max-aggr-func} 2| {num-result-aggr-func}
aggregate-function      ::= {non-num-aggregate-func} 2| {num-only-aggregate-func}

################################################################################
# Numeric constant values, functions, operators and expressions
#
digit                   ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9
non-negative-int-value  ::= {digit}[{digit}[{digit}][{non-negative-int-value}]]
integer-non-null-value  ::= [-]{non-negative-int-value}
numeric-non-null-value  ::= {integer-non-null-value}[.{non-negative-int-value}[{non-negative-int-value}]]

# Byte values as defined here run from -129 to 129; since byte is really
# defined as -127 to 127, a few of those values are illegal, which is OK
byte-start              ::= 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12
byte-non-null-value     ::= [-][{byte-start}]{digit}

# The "3" before the "|" makes the "byte-non-null-value", "integer-non-null-value",
# and "numeric-non-null-value" options 3 times as likely as the NULL option
byte-value              ::= {byte-non-null-value}    3| NULL
integer-value           ::= {integer-non-null-value} 3| NULL
numeric-value           ::= {numeric-non-null-value} 3| NULL

int-expression          ::= {integer-value}  2|     {int-column-name}  5|     {int-function-expr}  2| \
                            {aggregate-function}({int-expression})
byte-expression         ::= {byte-value}      |    {byte-column-name}  3|    {byte-function-expr}
numeric-expression      ::= {numeric-value} 20| {numeric-column-name} 30| {numeric-function-expr} 20| {int-expression} 20| \
                            {aggregate-function}({numeric-expression}) 9| {numeric-scalar-sub-q}

int-function-expr       ::= {int-expression} {math-operator} {int-expression} | \
                            {int-function-2args}({int-expression}, {int-expression}) | \
                            {int-valued-string-expr} | {int-valued-time-expr} | {int-valued-t-unit-expr}
byte-function-expr      ::= {byte-expression} {math-operator} {byte-expression} | \
                            {int-function-2args}({byte-expression}, {byte-expression})
numeric-function-expr   ::= {numeric-expression} {math-operator} {numeric-expression} | \
                            {math-function-0args}[()] | \
                            {math-function-1arg}({numeric-expression}) 14| \
                            {math-function-2args}({numeric-expression}, {numeric-expression}) | \
                            {num-valued-time-expr}
math-operator           ::= + | - | * | /
math-function-0args     ::= PI
math-function-1arg      ::= ABS | CEILING | EXP | FLOOR | LN | LOG | LOG10 | SQRT | SIN | COS | TAN | CSC | SEC | COT
math-function-2args     ::= POWER
int-function-2args      ::= MOD

################################################################################
# String (VARCHAR) constant values, functions, operators and expressions
#
character               ::= A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z | \
                            a | b | c | d | e | f | g | h | i | j | k | l | m | n | o | p | q | r | s | t | u | v | w | x | y | z | \
                            {digit} 10| . | , | ! | @ | # | $ | % | ^ | & | * | ( | ) | - | _ | + | =
characters              ::= [{character}][{character}][{character}[{characters}]]
string-non-null-value   ::= '{characters}'

# The "3" before the "|" makes the "string-non-null-value" option 3 times as
# likely as the NULL option, making NULL values less likely
string-value            ::= {string-non-null-value} 3| NULL
# TODO: make this into actual JSON strings:
json-value              ::= {string-value}

string-expression       ::= {string-value} 20| {string-column-name} 50| {string-function-expr} 20| \
                            {non-num-aggregate-func}({string-expression}) 9| {string-scalar-sub-q}
string-function-expr    ::= {string-expression} {string-operator} {string-expression} 2| \
                            {string-valued-int-expr}  4| {string-val-str-int-expr}  5| \
                            {string-val-num-int-expr} 2| {string-special-func-expr} 3| \
                            {string-function-1arg} ({string-expression}) 3| \
                            {string-function-2args}({string-expression}, {string-expression}) 2| \
                            {string-function-2args}({string-expression}, {string-expression}, {case-sensitivity})  2| \
                            {string-function-3args}({string-expression}, {string-expression}, {string-expression}) 2| \
                            {string-function-4args}({string-expression}, {string-expression}, {string-expression}, {string-expression})
string-operator         ::= || | +
string-function-1arg    ::= LOWER  | TRIM | UPPER
string-function-2args   ::= CONCAT | REGEXP_POSITION
string-function-3args   ::= CONCAT | REPLACE
string-function-4args   ::= CONCAT
# Optional third argument for the REGEXP_POSITION function
case-sensitivity        ::= 'c' | 'i' | {string-expression}

# Some functions of a string produce an integer value
int-valued-string-func  ::= CHAR_LENGTH | OCTET_LENGTH
# POSITION is a special case, due to the use of the IN keyword
int-valued-string-expr  ::= {int-valued-string-func}({string-expression}) 2| POSITION({string-expression} IN {string-expression})

# Some functions of an integer produce a string value
string-valued-int-func  ::= BIN | CHAR | HEX | SPACE
string-valued-int-expr  ::= {string-valued-int-func}({int-expression})

# Some functions of a string and an integer (or 2) produce a string value
string-val-str-int-func ::= LEFT | RIGHT | SUBSTRING
# We only allow byte values in the REPEAT function, because giving it large values can
# freeze VoltDB, consume all CPU time, and slow down your machine to a crawl; see ENG-12118
string-val-str-byte-fun ::= REPEAT
string-val-str-2int-fun ::= SUBSTRING
string-val-str-int-expr ::= {string-val-str-int-func}({string-expression}, {int-expression})  3| \
                            {string-val-str-byte-fun}({string-expression}, {byte-expression})  | \
                            {string-val-str-2int-fun}({string-expression}, {int-expression},  {int-expression})

# One function of 2 numbers (1 decimal and 1 integer) produces string values
string-val-num-int-func ::= FORMAT_CURRENCY
# One function of 1, 2, or 3 numbers (1 decimal and 2 optional integers) produces string values
string-val-num-2int-fun ::= STR
string-val-num-int-expr ::= {string-val-num-int-func}({numeric-expression}, {int-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}, {int-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}, {int-expression}, {int-expression})

# Some string functions use special keywords (e.g. PLACING, FROM, FOR)
string-special-func-expr::= OVERLAY({string-expression} PLACING {string-expression} FROM {int-expression} [FOR {int-expression}]) | \
                            SUBSTRING({string-expression} FROM {int-expression} [FOR {int-expression}]) | \
                            TRIM([[{trim-keyword} ]['{character}'] FROM ]{string-expression})
trim-keyword            ::= LEADING | TRAILING | BOTH

################################################################################
# Timestamp (date-time) constant values, functions, operators and expressions
#
month                   ::= 01 | 02 | 03 | 04 | 05 | 06 | 07 | 08 | 09 | 10 | 11 | 12
hour-more-than-12       ::= 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23
digit-0-to-5            ::= 0 | 1 | 2 | 3 | 4 | 5
century                 ::= 18 | 19 | 20 | 21 | {digit}{digit}
year                    ::= {century}{digit}{digit}

# The "12" or "11" before the "|" makes those options more likely, making all
# valid day or hour values equally likely
day                     ::= {month} 12| {hour-more-than-12} 11| 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31
hour                    ::= {month} 12| {hour-more-than-12} 11| 00
minute-or-second        ::= {digit-0-to-5}{digit}

# PostgreSQL-compatible version of the above: avoids April 31, February 29 in non-leap year, etc.
pg-day                  ::= {month} 12| {hour-more-than-12} 11| 24 | 25 | 26 | 27 | 28

timestamp-non-null-value::= '{year}-{month}-{day} {hour}:{minute-or-second}:{minute-or-second}[.{digit}{digit}{digit}]'

# The "3" before the "|" makes the "timestamp-non-null-value" option 3 times as
# likely as the NULL option, making NULL values less likely
timestamp-value         ::= {timestamp-non-null-value} 3| NULL

timestamp-expression    ::= {timestamp-value} 20| {timestamp-column-name} 50| {timestamp-function-expr} 20| \
                            {non-num-aggregate-func}({timestamp-expression}) 9| {timestamp-scalar-sub-q}
timestamp-function-expr ::= {timestamp-func-0args} 2| \
                            FROM_UNIXTIME({int-expression}) | \
                            TO_TIMESTAMP({short-time-unit}, {int-expression}) | \
                            TRUNCATE({dateadd-time-unit}, {timestamp-expression}) | \
                            DATEADD({dateadd-time-unit}, {int-expression}, {timestamp-expression})
timestamp-func-0args    ::= CURRENT_TIMESTAMP[()] | NOW[()]

# PostgreSQL-compatible version of the above: avoids presence or absence of parens not supported
pg-timestamp-func-0args ::= CURRENT_TIMESTAMP | NOW()

# Some functions of a timestamp produce an integer value
int-valued-time-func    ::= DAY | DAYOFMONTH | DAYOFWEEK | DAYOFYEAR | HOUR | MINUTE | \
                            MONTH | QUARTER | WEEK | WEEKOFYEAR | WEEKDAY | YEAR
int-valued-time-expr    ::= {int-valued-time-func}({timestamp-expression})

# One function of a timestamp produces a numeric (float) value
num-valued-time-func    ::= {int-valued-time-func} 3| SECOND
num-valued-time-expr    ::= {num-valued-time-func}({timestamp-expression})

# Some functions of a time-unit (string) and a timestamp produce an integer value
# (and EXTRACT optionally uses the special keyword FROM)
# Note: EXTRACT actually produces a decimal (not integer) when the SECOND time-unit is used,
# which may produce an error in some contexts, if an integer is expected - which is OK
int-valued-t-unit-expr  ::= SINCE_EPOCH({short-time-unit}, {timestamp-expression}) | \
                            EXTRACT({extract-time-unit}, {timestamp-expression}) | \
                            EXTRACT({extract-time-unit} FROM {timestamp-expression})

# Time units used in the definitions above:
long-time-unit          ::= YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE | SECOND
short-time-unit         ::= SECOND | MILLISECOND | MILLIS | MICROSECOND | MICROS
special-time-unit       ::= DAY_OF_MONTH | DAY_OF_WEEK | DAY_OF_YEAR | WEEK | WEEK_OF_YEAR | WEEKDAY
extract-time-unit       ::= {long-time-unit} | {special-time-unit}
dateadd-time-unit       ::= {long-time-unit} | {short-time-unit}

################################################################################
# Varbinary (binary) constant values, functions, operators and expressions
#
hex-alphabetic-digit    ::= A | B | C | D | E | F | a | b | c | d | e | f
hex-digit               ::= {digit} 2| {hex-alphabetic-digit}
even-num-of-hex-digits  ::= {hex-digit}{hex-digit}[{even-num-of-hex-digits}]
varbin-non-null-value   ::= x'{even-num-of-hex-digits}'

# The "3" before the "|" makes the "varbin-non-null-value" option 3 times as
# likely as the NULL option, making NULL values less likely
varbinary-value         ::= {varbin-non-null-value} 3| NULL

# TODO: flesh this part out, with varbinary functions, expressions ...
#varbinary-expression    ::= {varbinary-value} 20| {varbinary-column-name} 50| {varbinary-function-expr} 20| \
#                            {non-num-aggregate-func}({varbinary-expression}) 9| {varbinary-scalar-sub-q}
# This will do for now:
varbinary-expression    ::= {varbinary-column-name} 3| {varbinary-value}

################################################################################
# Geospatial Point constant values, functions, operators and expressions
#
# TODO: flesh this part out ...

digit-less-than-8       ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7
digit-less-than-9       ::= {digit-less-than-8} 8| 8
number-less-than-80     ::= {digit-less-than-8}[{digit}][.{non-negative-int-value}]
number-less-than-90     ::= {digit-less-than-9}[{digit}][.{non-negative-int-value}]
number-less-than-100    ::= {digit}[{digit}][.{non-negative-int-value}]

# Latitude is a number between -100 and 100 (exclusive); longitude is between
# -200 and 200 (exclusive); these include some illegal values, which is OK
latitude                ::= [-]{number-less-than-100}
longitude               ::= [-][1]{number-less-than-100}
point-non-null-value    ::= PointFromText('POINT({longitude} {latitude})')

# PostgreSQL-compatible version of the above: avoids differing treatment of illegal values:
# Latitude is a number between -90 and 90 (exclusive);
# longitude is between -180 and 180 (exclusive);
# illegal values not allowed, since they cause inconsistencies with PostgreSQL
pg-latitude             ::= [-]{number-less-than-90}
pg-longitude            ::= [-][1]{number-less-than-80}

# The "3" before the "|" makes the "point-non-null-value" option 3 times as
# likely as the NULL option, making NULL values less likely
point-value             ::= {point-non-null-value} 3| NULL

# TODO: flesh this part out, with point functions, expressions ...
#point-expression        ::= {point-value} 20| {point-column-name} 50| {point-function-expr} 20| \
#                            {non-num-aggregate-func}({point-expression}) 9| {point-scalar-sub-q}
# This will do for now:
point-expression        ::= {point-column-name} 3| {point-value}

################################################################################
# Geospatial Polygon constant values, functions, operators and expressions
#
# TODO: flesh this part out ...

# About a quarter of these simple polygons will be defined clockwise, hence invalid
polygon-non-null-value  ::= PolygonFromText('POLYGON((0 0, {longitude} 0, 0 {latitude}, 0 0))') | \
                            PolygonFromText('POLYGON((-2 -2, 10 -2, -2 10, -2 -2),(-1 -1, -1 {digit}, {digit} -1, -1 -1))')

# The "3" before the "|" makes the "polygon-non-null-value" option 3 times as
# likely as the NULL option, making NULL values less likely
polygon-value           ::= {polygon-non-null-value} 3| NULL

# TODO: flesh this part out, with polygon functions, expressions ...
#polygon-expression      ::= {polygon-value} 20| {polygon-column-name} 50| {polygon-function-expr} 20| \
#                            {non-num-aggregate-func}({polygon-expression}) 9| {polygon-scalar-sub-q}
# This will do for now:
polygon-expression      ::= {polygon-column-name} 3| {polygon-value}

################################################################################
# Non-geospatial (ng-) alternative values of some of the above definitions, for
# use with SQLCoverage, to avoid issues with Geospatial types (point & polygon,
# i.e. GEOGRAPHY_POINT & GEOGRAPHY); these definitions are largely the same,
# but with the points and polygons [and varbinary?] left out, or NULL
#
# Note: this section is not currently used, though it may be used in the future,
# in a version that feeds queries to SQLCoverage (see ENG-10240); though more
# likely it will be replaced by the various 'pg-...' definitions above.

ng-non-int-str-column-name ::= {timestamp-column-name} | {varbinary-column-name} | {int-column-name}

ng-random-type-value       ::= {integer-value} | {numeric-value} | {string-value} | {timestamp-value} | \
                               {varbinary-value}
ng-in-or-up-sert-values    ::= {insert-values-id-num}    | {insert-values-id-str}   | {insert-values-id-time} | \
                               {insert-values-id-varbin} | \
                               {insert-values-multiple}  | {insert-values-all}      | {insert-values-backward}
ng-in-or-up-sert-select    ::= {insert-select-id-num}    | {insert-select-id-str}   | {insert-select-id-time} | \
                               {insert-select-id-varbin} | \
                               {insert-select-multiple}  | {insert-select-all}      | {insert-select-backward}
ng-insert-values-multiple  ::= SERT INTO {table-name} (ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                               {varbinary-column-name} ) VALUES ({integer-non-null-value}, \
                               {numeric-value}, {string-value}, {timestamp-value}, {varbinary-value} )
ng-insert-values-all       ::= SERT INTO {table-name} ( \
                               ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN \
                               ) VALUES ( {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value}, {integer-value}, \
                               {numeric-value}, {numeric-value}, {string-value}, {string-value}, {string-value}, {timestamp-value}, \
                               {varbinary-value} )
ng-insert-values-backward  ::= SERT INTO {table-name} ( \
                               VARBIN, TIME, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT, SMALL, TINY, ID \
                               ) VALUES ( {varbinary-value}, {timestamp-value}, {string-value}, \
                               {string-value}, {string-value}, {numeric-value}, {numeric-value}, {integer-value}, {integer-value}, \
                               {integer-value}, {byte-value}, {integer-non-null-value} )
ng-insert-select-multiple  ::= SERT INTO {table-name} ( ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                               {varbinary-column-name} ) SELECT {int-column-name}, \
                               {numeric-column-name}, {string-column-name}, {timestamp-column-name}, {varbinary-column-name} \
                               FROM {table-reference}
ng-insert-select-all       ::= SERT INTO {table-name} ( \
                               ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN ) SELECT \
                               ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN FROM {table-reference}
ng-insert-select-backward  ::= SERT INTO {table-name} ( \
                               VARBIN, TIME, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT, SMALL, TINY, ID ) SELECT \
                               VARBIN, TIME, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT, SMALL, TINY, ID FROM {table-reference}
ng-star                    ::= ID, TINY, SMALL, INT, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME, VARBIN
ng-point-value             ::= NULL
ng-polygon-value           ::= NULL

