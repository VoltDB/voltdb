################################################################################
#
# This file defines the grammar for SQL statements of various types. The
# first section (Table names and Column names) is specific to the DDL table
# definitions that are used, along with this file, to test VoltDB; but most of
# the rest (with certain exceptions, like table and column aliases, and polygon
# values) is (intended to be) completely general, albeit it will need to be
# added to whenever new SQL functions or other features are added to VoltDB.
#
# The parser that interprets this file understands only a few simple rules:
#   1. The ::= symbol means "is defined as". Definitions are normally given on
#      a single line, but may be continued onto one or more additional lines
#      using a backslash (\) as a continuation character; the backslash must
#      be the last character on the line.
#   2. The {foo} syntax means to use symbol "foo", which is defined somewhere
#      in this file, using "::="; recursive definitions are allowed, though of
#      course a non-recursive option must also be available, to avoid infinite
#      recursion.
#   3. The | symbol means "or" (actually, XOR), with an equal probability of
#      each possible option being chosen, by default (but see #6 below). The |
#      must be preceded and followed by a space (otherwise the || concatenation
#      operator would be impossible without some sort of escape symbol, which
#      I did not want to get into).
#   4. Something in brackets, such as [foo], is optional, with a 50-50 chance
#      of being included; If you want to make something optional less likely,
#      add more brackets, e.g., [[foo]] has only a 25% chance of being included.
#   5. You cannot include | inside brackets, so [foo | bar] will not work
#      properly, though the reverse, e.g. [foo] | [bar] is fine; to achieve
#      the same effect as [foo | bar] use [{foo-or-bar}], with:
#          foo-or-bar ::= foo | bar
#      See "all-or-distinct" for one example of this.
#
# Later extensions to the original, simple syntax:
#   6. Adding a (positive) integer before a | symbol makes the preceding option
#      more likely; the "n|" still needs to be preceded and followed by a space.
#      For example, in this definition:
#          definition ::= foo 2| bar
#      the "foo" option is twice as likely as the "bar" option. You may use
#      more than one such integer; for example, in this definition:
#          definition ::= foo 3| bar 2| null
#      the "foo" option will be chosen half (3/6) the time, the "bar" option
#      will be chosen a third (2/6) of the time, and the "null" option will
#      be chosen only 1 time in 6. Note that the last option always has an
#      implicit "likelihood weight" of 1, as do any options preceded simply with
#      a |. The actual probability of each option is its "likelihood weight"
#      divided by the sum of all the "likelihood weights" of all options.
#   7. It is now possible (despite what it says in #3 above) to escape an open
#      ("[") or close ("]") bracket symbol, by preceding it with a backslash,
#      i.e., "\[" or "\]"; these escaped versions will be interpreted as literal
#      bracket symbols ("[" or "]"), rather than as containing optional text.
#   8. Similarly, an open or close curly brace, or an actual backslash, may
#      also be escaped by preceding it with a backslash; i.e., "\{", "\}, and
#      "\\" will be interpreted as those literal characters, that is, as "{",
#      "}, and "\", respectively.
#   9. If you want to refer to the same name, e.g. a table name, twice in the
#      same SQL statement, you may use the following colon syntax, to specify
#      a reusable name: {table-name:t1}; and a subsequent reference can either
#      use that syntax again, or simply {:t1}, if you're sure that
#      {table-name:t1} has already been used in the same SQL statement. The
#      first time that {table-name:t1} is evaluated, one of the possible values
#      of {table-name} will be selected, e.g. "R1" or "P2", and then that value
#      becomes associated with {:t1}, and will be used again whenever {...:t1}
#      appears, even if it's in, say, {view-name:t1}.
#  10. If you want to refer to one of several reusable names (as defined in #9
#      above) that have been defined elsewhere in the same SQL statement, e.g.
#      one of several table names, you may use the following semicolon syntax:
#      {table-name;t1,t2,t3,t4,t5}. This will be evaluated to be equal to one of
#      the reusable names {:t1}, {:t2}, {:t3}, {:t4}, or {:t5}; however, it will
#      only select a reusable name that has already been defined elsewhere in
#      the same SQL statement. If multiple reusable names have been defined, one
#      will be selected using a diminishing probability (e.g., {:t1} is most
#      likely in the example above, and {:t5} is least likely); if and only if
#      none of the reusable names has been defined, then {table-name} will be
#      evaluated in the normal manner, as if the semicolon syntax were omitted.
#      Definitions using the colon syntax are evaluated first, and definitions
#      using the semicolon syntax are evaluated last, to maximize the chances
#      for a reusable name having already been defined. This technique is useful
#      in specifying column references that refer to a legitimate table (or view
#      or sub-query) name (or alias); for example, R1.ID only makes sense if
#      table R1 has been specified elsewhere in the SQL statement, so using a
#      definition such as {table-name;t1,t2,t3,t4,t5}.{any-column-name} makes
#      this much more likely.
#  11. An addition to the colon syntax for reusable names, described in #9
#      above: if you wish to set multiple (possibly unique) values to multiple
#      reusable names, you may use, for example, this syntax:
#      {column-name:c1,c2,c3,c4,c5:10}. The first time that this is used (in a
#      given SQL statement), it will find one possible value of {column-name},
#      and set 'c1' equal to that; the second time, it will find another
#      possible value, and set 'c2' to that; the third time, to 'c3', etc. The
#      final number after the second colon, here '10', means that there is a 10%
#      chance that repeat values of {column-name} will be allowed; if that value
#      is instead '0', then distinct values of {column-name} will be used, with
#      no duplicates, though if it runs out of distinct possible values of
#      {column-name}, or out of reusable names, then duplicates will be used.
#      The second colon and the repeat-percentage following it are optional; if
#      not specified, there will be no attempt to avoid repeats.
#  12. An addition to the semi-colon syntax for reusable names, described in
#      #10 above: if you wish to get a list of reusable values, such as those
#      defined in #11 above, you may use, for example, this syntax:
#      {column-name;c1,c2,c3,c4,c5;', '}. This will produce a list of all the
#      values of all of the reusable names listed, separated by the separator
#      string (here, ', '); any reusable names that have not yet been given
#      values (e.g., 'c4, 'c5') will be omitted from the list. The second semi-
#      colon and the separator string are required to get a list in this manner,
#      but the separator string may be the empty string, ''.
#
################################################################################

################################################################################
# Table, view, and stored procedure names pre-defined in the DDL associated with
# this test (and very occasionally, a nonexistent table name, view name, stored
# procedure name, or, below, column name is used)

# Table names broken down by the number and data type(s) of their primary key;
# this includes both Replicated and Partitioned Tables:
table-name-w-no-pk      ::= R0 | P0
table-name-w-pk-int     ::= R1 9| P1 9| R2 9| P2 9| R11 9| P11 9| R12 | P12 | R13 9| P13 9| R14 | P14
table-name-w-pk-str     ::= R3 | P3
table-name-w-pk-int-str ::= R4 | P4
table-name-w-pk-str-int ::= R5 | P5
table-name-w-pk-varbin  ::= R6 | P6
table-name-w-pk-i-s-v   ::= R7 | P7

# These tables are declared with TTL columns and/or MIGRATE targets:
table-w-ttl-column-only ::= R21 | P21
table-w-migrate-only    ::= R31 | P31
table-name-w-migrate    ::= {table-w-migrate-only}
table-name-ttl-or-migr  ::= {table-w-migrate-only} | {table-w-ttl-column-only}

# These are definitions that are to be used only when running SQL grammar
# generator with the 'pro' version of VoltDB, due to the limited number of
# streams in 'community'
table-w-ttl-and-migrate ::= R141 | P141
pro-table-name-w-migrate::= {table-w-migrate-only} | {table-w-ttl-and-migrate}
pro-tbl-name-ttl-or-migr::= {table-w-ttl-column-only} | {pro-table-name-w-migrate}

# Stream names are also only to be used only when running SQL grammar generator
# with the 'pro' version of VoltDB; so they're set to something else, otherwise
stream-name             ::= {ddl-table-name}
pro-stream-name         ::= S100

# MIGRATE (DML) statements will usually use a table with a declared MIGRATE
# target; but occasionally will use a regular, non-MIGRATE table, which is
# invalid, so it should return a reasonable error message but not crash
migrate-table-name      ::= {table-name-w-migrate} 19| {table-or-view-name}

# Only identical tables (including indexes) without views can be swapped;
# the swap of two generic {table-name} will usually not work, but should
# return a reasonable error message (commas and single quotes are optional)
swappable-tables        ::= R11[,] R12 | P11[,] P12 | R13[,] R14 | P13[,] P14 | \
                            R12[,] R11 | P12[,] P11 | R14[,] R13 | P14[,] P13 | \
                            R11[,] 'R12' | P11[,] 'P12' | R13[,] 'R14' | P13[,] 'P14' | \
                            R12[,] 'R11' | P12[,] 'P11' | R14[,] 'R13' | P14[,] 'P13' | \
                            'R11'[,] R12 | 'P11'[,] P12 | 'R13'[,] R14 | 'P13'[,] P14 | \
                            'R12'[,] R11 | 'P12'[,] P11 | 'R14'[,] R13 | 'P14'[,] P13 | \
                            'R11'[,] 'R12' | 'P11'[,] 'P12' | 'R13'[,] 'R14' | 'P13'[,] 'P14' | \
                            'R12'[,] 'R11' | 'P12'[,] 'P11' | 'R14'[,] 'R13' | 'P14'[,] 'P13' | \
                            {table-name}[,] {table-name} | '{table-name}'[,] '{table-name}'

legit-table-name        ::= {ddl-table-name}         5| {stream-name} | \
                            {table-name-ttl-or-migr} 5| {table-name-w-no-pk}      | \
                            {table-name-w-pk-int}    4| {table-name-w-pk-str}     | \
                            {table-name-w-pk-int-str} | {table-name-w-pk-str-int} | \
                            {table-name-w-pk-varbin}  | {table-name-w-pk-i-s-v}

legit-view-name         ::= {ddl-view-name} 6| \
                            VR1 | VP1 | VR2 | VP2 | VR3 | VP3 | VR4 | VP4 | \
                            VR5 | VP5 | VR6 | VP6 | VR7 | VP7

table-name              ::= {legit-table-name} 199| NONEXISTENT_TABLE
view-name               ::= {legit-view-name}  199| NONEXISTENT_VIEW
table-or-view-name      ::= {table-name} 3| {view-name}

########################################
# User-defined Stored Procedures: this includes both Java and SQL Stored
# Procedures; e.g., SSPR1min is a SQL Stored Procedure that returns the MIN ID
# from table R1, JSPP1insMax is a Java Stored Procedure that inserts a row with
# a new MAX ID (the old MAX(ID)+1) into table P1, etc.; "random" (SQL) Stored
# Procs are not predetermined in the DDL file, but rather created on the fly
user-proc-name          ::= {user-proc-0params} 2| {user-proc-1param}
java-proc-name          ::= {java-proc-0params} 2| {java-proc-1param}

# TODO: the "random" (SQL) Stored Procs are the most interesting, and therefore
# weighted the highest here; but we could potentially generate Java Stored Procs
# using randomly generated SQL statements (not an easy task), in which case we
# would want to reevaluate these weights (same comment potentially applies to
# user-proc-1param below)
user-proc-0params       ::= {random-proc-0params} 139| {sql-proc-0params} 40| \
                            {java-proc-0params}    20| NONEXISTENT_PROC
# TODO: could add more Java Stored Procs, for more tables (or random ones)
java-proc-0params       ::= JSPR1min | JSPR1max | JSPR1insMin | JSPR1insMax | \
                            JSPP1min | JSPP1max | JSPP1insMin | JSPP1insMax
sql-proc-0params        ::= SSPR0min | SSPR0max | SSPR0insMin | SSPR0insMax | \
                            SSPP0min | SSPP0max | SSPP0insMin | SSPP0insMax | \
                            SSPR1min | SSPR1max | SSPR1insMin | SSPR1insMax | \
                            SSPP1min | SSPP1max | SSPP1insMin | SSPP1insMax | \
                            SSPR2min | SSPR2max | SSPR2insMin | SSPR2insMax | \
                            SSPP2min | SSPP2max | SSPP2insMin | SSPP2insMax | \
                            SSPR3min | SSPR3max | SSPR3insMin | SSPR3insMax | \
                            SSPP3min | SSPP3max | SSPP3insMin | SSPP3insMax | \
                            SSPR4min | SSPR4max | SSPR4insMin | SSPR4insMax | \
                            SSPP4min | SSPP4max | SSPP4insMin | SSPP4insMax | \
                            SSPR5min | SSPR5max | SSPR5insMin | SSPR5insMax | \
                            SSPP5min | SSPP5max | SSPP5insMin | SSPP5insMax | \
                            SSPR6min | SSPR6max | SSPR6insMin | SSPR6insMax | \
                            SSPP6min | SSPP6max | SSPP6insMin | SSPP6insMax | \
                            SSPR7min | SSPR7max | SSPR7insMin | SSPR7insMax | \
                            SSPP7min | SSPP7max | SSPP7insMin | SSPP7insMax
random-proc-0params     ::= RPROC{digit-0-to-5}

# TODO: get "random" (SQL) Stored Procs with 1 parameter (or more?) working
user-proc-1param        ::= {random-proc-1param}  0| {sql-proc-1param} 133| \
                            {java-proc-1param}   66| NONEXISTENT_PROC
# TODO: could add more Java Stored Procs, for more tables
java-proc-1param        ::= JSPR1ins | JSPR1sel | JSPP1ins | JSPP1sel
sql-proc-1param         ::= SSPR0ins | SSPR0sel | SSPP0ins | SSPP0sel | \
                            SSPR1ins | SSPR1sel | SSPP1ins | SSPP1sel | \
                            SSPR2ins | SSPR2sel | SSPP2ins | SSPP2sel | \
                            SSPR3ins | SSPR3sel | SSPP3ins | SSPP3sel | \
                            SSPR4ins | SSPR4sel | SSPP4ins | SSPP4sel | \
                            SSPR5ins | SSPR5sel | SSPP5ins | SSPP5sel | \
                            SSPR6ins | SSPR6sel | SSPP6ins | SSPP6sel | \
                            SSPR7ins | SSPR7sel | SSPP7ins | SSPP7sel
# TODO: could define random (SQL) Stored Procs, that take 1 parameter (or more?)
random-proc-1param      ::= RPROC6 | RPROC7 | RPROC8 | RPROC9

########################################
# Column names used in the pre-defined DDL, of every possible data type ...
byte-column-name        ::= TINY
int-non-small-non-id-col::= INT1 | BIG
int-non-small-col-name  ::= {int-non-small-non-id-col} 2| ID
int-non-id-column-name  ::= {int-non-small-non-id-col} 2| {byte-column-name} | SMALL
int-column-name         ::= {int-non-id-column-name}   4| ID

# The "5" before the "|" makes the "int-column-name" option 5 times as likely
# as the other options, making each numeric column name equally likely
numeric-column-name     ::= {int-column-name}        5| NUM | DEC
numeric-non-id-col-name ::= {int-non-id-column-name} 4| NUM | DEC

string-column-name      ::= VCHAR_INLINE | VCHAR_INLINE_MAX | VCHAR_OUTLINE_MIN | VCHAR
timestamp-column-name   ::= TIME1
varbinary-column-name   ::= VARBIN
point-column-name       ::= POINT
polygon-column-name     ::= POLYGON
geo-column-name         ::= {point-column-name} | {polygon-column-name}
non-int-str-column-name ::= {geo-column-name} 2| {timestamp-column-name} | {varbinary-column-name}

# PostgreSQL-compatible version of the above: avoids problems involving SELECT with Geospatial types
pg-point-column-name    ::= _variable\[point\]
pg-polygon-column-name  ::= _variable\[polygon\]

# For now, at least, TABLE and VIEW column names are the same
table-column-name       ::= {numeric-column-name} 2| {string-column-name} | {non-int-str-column-name}
view-column-name        ::= {table-column-name}
legit-column-name       ::= {table-column-name} 3| {view-column-name}
column-name             ::= {legit-column-name} 999| NONEXISTENT_COLUMN
column-list             ::= {column-name} [, {column-list}]
column-expression-list  ::= {column-expression} [, {column-expression-list}]

# These versions include the JSON and 'internet' columns (used with the INET... functions),
# which we don't normally want to set to invalid values (but selecting them is fine)
json-column-name        ::= VCHAR_JSON
string-ipv4-column-name ::= IPV4
string-ipv6-column-name ::= IPV6
string-ipv-column-name  ::= {string-ipv4-column-name} | {string-ipv6-column-name}
varbin-ipv4-column-name ::= VBIPV4
varbin-ipv6-column-name ::= VBIPV6
varbin-ipv-column-name  ::= {varbin-ipv4-column-name} | {varbin-ipv6-column-name}
any-string-column-name  ::= {string-column-name} 4| {string-ipv-column-name} 2| {json-column-name}
any-varbin-column-name  ::= {varbin-ipv-column-name} 2| {varbinary-column-name}
any-table-column-name   ::= {table-column-name} 15| {varbin-ipv-column-name} 2| {string-ipv-column-name} 2| {json-column-name}
any-view-column-name    ::= {any-table-column-name}
any-legit-column-name   ::= {any-table-column-name} 3| {any-view-column-name}
any-column-name         ::= {any-legit-column-name} 999| NONEXISTENT_COLUMN

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
# (and in the appropriate section above)
every-column-name       ::= ID, TINY, SMALL, INT1, BIG, NUM, DEC, \
                            VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR_OUTLINE_MIN, VCHAR, VCHAR_JSON, \
                            TIME1, VARBIN, POINT, POLYGON, \
                            IPV4, IPV6, VBIPV4, VBIPV6
every-col-name-backward ::= VBIPV6, VBIPV4, IPV6, IPV4, \
                            POLYGON, POINT, VARBIN, TIME1, \
                            VCHAR_JSON, VCHAR, VCHAR_OUTLINE_MIN, VCHAR_INLINE_MAX, VCHAR_INLINE, \
                            DEC, NUM, BIG, INT1, SMALL, TINY, ID
# With the string (VARCHAR) columns listed first
# TODO: these are not currently used
every-column-name-str   ::= VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR_OUTLINE_MIN, VCHAR, VCHAR_JSON, \
                            ID, TINY, SMALL, INT1, BIG, NUM, DEC, \
                            TIME1, VARBIN, POINT, POLYGON, \
                            IPV4, IPV6, VBIPV4, VBIPV6
every-column-name-gb    ::= TINY, SMALL, ID, INT1, BIG, NUM, DEC, \
                            VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR_OUTLINE_MIN, VCHAR, VCHAR_JSON, \
                            TIME1, VARBIN, POINT, POLYGON, \
                            IPV4, IPV6, VBIPV4, VBIPV6
every-column-name-str-gb::= VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR_OUTLINE_MIN, VCHAR, VCHAR_JSON, \
                            ID, TINY, SMALL, INT1, BIG, NUM, DEC, \
                            TIME1, VARBIN, POINT, POLYGON, \
                            IPV4, IPV6, VBIPV4, VBIPV6

# These are obviously not the complete lists of all possible table and column
# aliases, but using a short list makes it more likely that when you refer to
# one it is one that was actually defined
table-alias             ::= TA1 96| TA2 48| TA3 24| TA4 12| TA5 6| TA6 3| TA7 2| TA8
column-alias            ::= CA1 96| CA2 48| CA3 24| CA4 12| CA5 6| CA6 3| CA7 2| CA8

########################################
# These '...-set' definitions (using ':t1', ':t2', etc.) are used to set a
# table (or view or sub-query) name or alias that may be referred to elsewhere
# in the SQL statement
table-name-set          ::= {table-name:t1} 6| \
                            {table-name:t2} 6| \
                            {table-name:t3} 3| \
                            {table-name:t4} 2| \
                            {table-name:t5}
view-name-set           ::= {view-name:t1} 6| \
                            {view-name:t2} 6| \
                            {view-name:t3} 3| \
                            {view-name:t4} 2| \
                            {view-name:t5}
table-alias-set         ::= {table-name} [AS ]{table-alias:t1} 6| \
                            {table-name} [AS ]{table-alias:t2} 6| \
                            {table-name} [AS ]{table-alias:t3} 3| \
                            {table-name} [AS ]{table-alias:t4} 2| \
                            {table-name} [AS ]{table-alias:t5}
view-alias-set          ::= {view-name} [AS ]{table-alias:t1} 6| \
                            {view-name} [AS ]{table-alias:t2} 6| \
                            {view-name} [AS ]{table-alias:t3} 3| \
                            {view-name} [AS ]{table-alias:t4} 2| \
                            {view-name} [AS ]{table-alias:t5}
sub-query-set           ::= {sub-query} [AS ]{table-alias:t1} 6| \
                            {sub-query} [AS ]{table-alias:t2} 6| \
                            {sub-query} [AS ]{table-alias:t3} 3| \
                            {sub-query} [AS ]{table-alias:t4} 2| \
                            {sub-query} [AS ]{table-alias:t5}

# Same as above, but for tables created with TTL and/or MIGRATE clauses
migrate-table-name-set  ::= {migrate-table-name:t1} 6| \
                            {migrate-table-name:t2} 6| \
                            {migrate-table-name:t3} 3| \
                            {migrate-table-name:t4} 2| \
                            {migrate-table-name:t5}

# Special case: when a "T0" table alias gets used, make sure that it gets "set"
# as one of the table definitions (':t1', ':t2', etc.) used above
t0-set                  ::= T0
t0                      ::= {t0-set:t5} 6| \
                            {t0-set:t4} 6| \
                            {t0-set:t3} 3| \
                            {t0-set:t2} 2| \
                            {t0-set:t1}

table-name-or-alias-set ::= {table-name-set} 3| {table-alias-set}
view-name-or-alias-set  ::= {view-name-set}  3| {view-alias-set}

table-ref-set           ::= {table-name-or-alias-set} 7| \
                            {view-name-or-alias-set}  2| \
                            {sub-query-set}

########################################
# These '...-ref' definitions (using ';t1,t2,t3,t4,t5') are used to refer to a
# table (or view or sub-query) name or alias that was previously set, elsewhere
# in the SQL statement
table-name-ref          ::= {table-name;t1,t2,t3,t4,t5}
table-alias-ref         ::= {table-alias;t1,t2,t3,t4,t5}
view-name-ref           ::= {view-name;t1,t2,t3,t4,t5}
table-ref               ::= {table-name-ref} 2| {table-alias-ref} 2| {view-name-ref}

# The use of "{table-ref}" is useful to refer to a table name or alias that has
# already been defined, elsewhere in the SQL statement
column-table-ref        ::= {table-ref}.{any-column-name} 19| {any-column-name}

########################################
# Same '...-set' and '...-ref' ideas as above, but here for a column alias
column-alias-set        ::= {column-alias:ca0} | \
                            {column-alias:ca1} | \
                            {column-alias:ca2} | \
                            {column-alias:ca3} | \
                            {column-alias:ca4} | \
                            {column-alias:ca5} | \
                            {column-alias:ca6} | \
                            {column-alias:ca7} | \
                            {column-alias:ca8} | \
                            {column-alias:ca9}
column-alias-ref        ::= {column-alias;ca0,ca1,ca2,ca3,ca4,ca5,ca6,ca7,ca8,ca9,cj1,cj2,cj3,cj4}

################################################################################
# Any SQL statement (this now includes some DDL statements):
# The "50" before the first "|" makes the "select-statement" option 50 times as
# likely as the least likely (last) option; so half of these SQL statements will
# be SELECT statements; but only 1% will be "ddl-statement", since we don't want
# to change the schema too often. Similarly, only 1% will be "delete-statement",
# since we don't want to delete all the rows in a table too often.
#
sql-statement           ::= {select-statement} 50| {cte-statement}     5| \
                            {dml-statement}    40| {sqlcmd-statement}  4| \
                            {ddl-statement}

dml-statement           ::= {insert-statement} 10| {upsert-statement}  10| \
                            {update-statement} 10| {migrate-statement}  9| \
                            {delete-statement}

################################################################################
# Grammar rules for an INSERT statement:
################################################################################
#
insert-statement        ::= {insert-values-statement} 2| {insert-select-statement}

# The "9" before the "|" makes the "simple-insert-values" or "ordered-values-list"
# option 9 times as likely as the other option, making simple, ordered, valid
# statements more likely
insert-values-statement ::= {simple-insert-values} 9| {insert-clause} VALUES ({values-list})
insert-select-statement ::= {simple-insert-select} 9| {insert-clause} {select-statement}
values-list             ::= {ordered-values-list}  9| {random-order-value-list}

# Putting "({column-list})" in more than one set of brackets makes it less likely
insert-clause           ::= INSERT INTO {table-name} [[({column-list})]]

ordered-values-list     ::= {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value}, {integer-value}, \
                            {numeric-value}, {numeric-value}, {string-value}, {string-value}, {string-value}, \
                            {timestamp-value}, {varbinary-value}, {point-value}, {polygon-value}
random-order-value-list ::= {random-type-value} [, {random-order-value-list}]
random-type-value       ::= {integer-value}  4| {numeric-value} 2| {string-value} 4| {timestamp-value} | \
                            {varbinary-value} | {point-value}    | {polygon-value} | {scalar-sub-query}
simple-insert-values    ::= IN{in-or-up-sert-values}
simple-insert-select    ::= IN{in-or-up-sert-select}

in-or-up-sert-values    ::= {insert-values-multiple}  8| {insert-values-all}     22| {insert-values-backward} 22| \
                            {insert-values-id-num}    7| {insert-values-id-str}   4| {insert-values-id-time}    | \
                            {insert-values-id-varbin}  | {insert-values-id-point}  | {insert-values-id-poly}    | \
                            {insert-values-id-json}    | {insert-vals-id-str-ipv4} | {insert-vals-id-str-ipv6}  | \
                            {insert-vals-id-varb-ipv4} | {insert-vals-id-varb-ipv6}
in-or-up-sert-select    ::= {insert-select-multiple} 8| {insert-select-all}    22| {insert-select-backward} 22| \
                            {insert-select-id-num}   7| {insert-select-id-str}  4| {insert-select-id-time}    | \
                            {insert-select-id-varbin} | {insert-select-id-point} | {insert-select-id-poly}    | \
                            {insert-select-id-json}   | {insert-sel-id-str-ipv4} | {insert-sel-id-str-ipv6}   | \
                            {insert-sel-id-varb-ipv4} | {insert-sel-id-varb-ipv6}

# We leave the IN off of INSERT here, so these can also be used for UPSERT
insert-values-id-num    ::= SERT INTO {table-name-set} (ID, {numeric-non-id-col-name}) VALUES ({integer-non-null-value},  {numeric-value-or-subq})  | \
                            SERT INTO {table-name-set} ({numeric-non-id-col-name}, ID) VALUES ({numeric-value-or-subq},   {integer-non-null-value}) | \
                            SERT INTO {table-name-set} (ID, {int-non-id-column-name})  VALUES ({integer-non-null-value},  {integer-value-or-subq})  | \
                            SERT INTO {table-name-set} ({int-non-id-column-name}, ID)  VALUES ({integer-value-or-subq},   {integer-non-null-value})
insert-values-id-str    ::= SERT INTO {table-name-set} (ID, {string-column-name})      VALUES ({integer-non-null-value},  {string-value-or-subq}) | \
                            SERT INTO {table-name-set} ({string-column-name}, ID)      VALUES ({string-value-or-subq},    {integer-non-null-value})
insert-values-id-time   ::= SERT INTO {table-name-set} (ID, {timestamp-column-name})   VALUES ({integer-non-null-value},  {timestamp-value-or-subq}) | \
                            SERT INTO {table-name-set} ({timestamp-column-name}, ID)   VALUES ({timestamp-value-or-subq}, {integer-non-null-value})
insert-values-id-varbin ::= SERT INTO {table-name-set} (ID, {varbinary-column-name})   VALUES ({integer-non-null-value},  {varbinary-value-or-subq}) | \
                            SERT INTO {table-name-set} ({varbinary-column-name}, ID)   VALUES ({varbinary-value-or-subq}, {integer-non-null-value})
insert-values-id-point  ::= SERT INTO {table-name-set} (ID, {point-column-name})       VALUES ({integer-non-null-value},  {point-value-or-subq}) | \
                            SERT INTO {table-name-set} ({point-column-name}, ID)       VALUES ({point-value-or-subq},     {integer-non-null-value})
insert-values-id-poly   ::= SERT INTO {table-name-set} (ID, {polygon-column-name})     VALUES ({integer-non-null-value},  {polygon-value-or-subq}) | \
                            SERT INTO {table-name-set} ({polygon-column-name}, ID)     VALUES ({polygon-value-or-subq},   {integer-non-null-value})
insert-values-id-json   ::= SERT INTO {table-name-set} (ID, {json-column-name})        VALUES ({integer-non-null-value},  {json-value-or-subq}) | \
                            SERT INTO {table-name-set} ({json-column-name}, ID)        VALUES ({json-value-or-subq},      {integer-non-null-value})
insert-vals-id-str-ipv4 ::= SERT INTO {table-name-set} (ID, {string-ipv4-column-name}) VALUES ({integer-non-null-value},  {str-ipv4-value-or-subq}) | \
                            SERT INTO {table-name-set} ({string-ipv4-column-name}, ID) VALUES ({str-ipv4-value-or-subq},  {integer-non-null-value})
insert-vals-id-str-ipv6 ::= SERT INTO {table-name-set} (ID, {string-ipv6-column-name}) VALUES ({integer-non-null-value},  {str-ipv6-value-or-subq}) | \
                            SERT INTO {table-name-set} ({string-ipv6-column-name}, ID) VALUES ({str-ipv6-value-or-subq},  {integer-non-null-value})
insert-vals-id-varb-ipv4::= SERT INTO {table-name-set} (ID, {varbin-ipv4-column-name}) VALUES ({integer-non-null-value},  {varb-ipv4-value-or-subq}) | \
                            SERT INTO {table-name-set} ({varbin-ipv4-column-name}, ID) VALUES ({varb-ipv4-value-or-subq}, {integer-non-null-value})
insert-vals-id-varb-ipv6::= SERT INTO {table-name-set} (ID, {varbin-ipv6-column-name}) VALUES ({integer-non-null-value},  {varb-ipv6-value-or-subq}) | \
                            SERT INTO {table-name-set} ({varbin-ipv6-column-name}, ID) VALUES ({varb-ipv6-value-or-subq}, {integer-non-null-value})

numeric-value-or-subq   ::= {numeric-value}     9| {numeric-scalar-sub-q}
integer-value-or-subq   ::= {integer-value}     9| {integer-scalar-sub-q}
byte-value-or-subq      ::= {byte-value}        9| {integer-scalar-sub-q}
string-value-or-subq    ::= {string-value}      9| {string-scalar-sub-q}
json-value-or-subq      ::= {json-text-value}   9| {json-scalar-sub-q}
timestamp-value-or-subq ::= {timestamp-value}   9| {timestamp-scalar-sub-q}
varbinary-value-or-subq ::= {varbinary-value}   9| {varbinary-scalar-sub-q}
point-value-or-subq     ::= {point-value}       9| {point-scalar-sub-q}
polygon-value-or-subq   ::= {polygon-value}     9| {polygon-scalar-sub-q}
str-ipv4-value-or-subq  ::= {string-ipv4-value} 9| {str-ipv4-scalar-sub-q}
str-ipv6-value-or-subq  ::= {string-ipv6-value} 9| {str-ipv6-scalar-sub-q}
varb-ipv4-value-or-subq ::= {varbin-ipv4-value} 9| {varb-ipv4-scalar-sub-q}
varb-ipv6-value-or-subq ::= {varbin-ipv6-value} 9| {varb-ipv6-scalar-sub-q}

insert-values-multiple  ::= SERT INTO {table-name-set} ( ID, {numeric-non-id-col-name}, {string-column-name}, {timestamp-column-name}, \
                            {varbinary-column-name}, {point-column-name}, {polygon-column-name} ) VALUES ( {insert-values-mult-val} )
insert-values-all       ::= SERT INTO {table-name-set} [({every-column-name})]     VALUES ( {insert-values-all-val} )
insert-values-backward  ::= SERT INTO {table-name-set} ({every-col-name-backward}) VALUES ( {insert-values-back-val} )

insert-values-mult-val  ::= {insert-values-mult-val1} 4| {insert-values-mult-val2}
insert-values-mult-val1 ::= {integer-non-null-value}, {numeric-value}, {string-value}, {timestamp-value}, \
                            {varbinary-value}, {point-value}, {polygon-value}
insert-values-mult-val2 ::= {integer-non-null-value}, {numeric-value-or-subq}, {string-value-or-subq}, {timestamp-value-or-subq}, \
                            {varbinary-value-or-subq}, {point-value-or-subq}, {polygon-value-or-subq}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
insert-values-all-val   ::= {insert-values-all-val1} 4| {insert-values-all-val2}
insert-values-all-val1  ::= {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value}, \
                            {integer-value}, {numeric-value}, {numeric-value}, \
                            {string-value}, {string-value}, {string-value}, {string-value}, {json-text-value}, \
                            {timestamp-value}, {varbinary-value}, {point-value}, {polygon-value}, \
                            {string-ipv4-value}, {string-ipv6-value}, {varbin-ipv4-value}, {varbin-ipv6-value}
insert-values-all-val2  ::= {integer-non-null-value}, {byte-value-or-subq}, {integer-value-or-subq}, {integer-value-or-subq}, \
                            {integer-value-or-subq}, {numeric-value-or-subq}, {numeric-value-or-subq}, \
                            {string-value-or-subq}, {string-value-or-subq}, {string-value-or-subq}, \
                            {string-value-or-subq}, {json-value-or-subq}, \
                            {timestamp-value-or-subq}, {varbinary-value-or-subq}, {point-value-or-subq}, {polygon-value-or-subq}, \
                            {str-ipv4-value-or-subq}, {str-ipv6-value-or-subq}, {varb-ipv4-value-or-subq}, {varb-ipv6-value-or-subq}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
insert-values-back-val  ::= {insert-values-back-val1} 4| {insert-values-back-val2}
insert-values-back-val1 ::= {varbin-ipv6-value}, {varbin-ipv4-value}, {string-ipv6-value}, {string-ipv4-value}, \
                            {polygon-value}, {point-value}, {varbinary-value}, {timestamp-value}, \
                            {json-text-value}, {string-value}, {string-value}, {string-value}, {string-value}, \
                            {numeric-value}, {numeric-value}, {integer-value}, {integer-value}, \
                            {integer-value}, {byte-value}, {integer-non-null-value}
insert-values-back-val2 ::= {varb-ipv6-value-or-subq}, {varb-ipv4-value-or-subq}, {str-ipv6-value-or-subq}, {str-ipv4-value-or-subq}, \
                            {polygon-value-or-subq}, {point-value-or-subq}, {varbinary-value-or-subq}, {timestamp-value-or-subq}, \
                            {json-value-or-subq}, {string-value-or-subq}, {string-value-or-subq}, \
                            {string-value-or-subq}, {string-value-or-subq}, \
                            {numeric-value-or-subq}, {numeric-value-or-subq}, {integer-value-or-subq}, {integer-value-or-subq}, \
                            {integer-value-or-subq}, {byte-value-or-subq}, {integer-non-null-value}

insert-select-id-num    ::= SERT INTO {table-name-set} (ID, {numeric-non-id-col-name}) SELECT {int-column-name}, {numeric-col-or-subq}   FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({numeric-non-id-col-name}, ID) SELECT {numeric-col-or-subq}, {int-column-name}   FROM {table-ref-set} | \
                            SERT INTO {table-name-set} (ID, {int-non-id-column-name})  SELECT {int-column-name}, {integer-col-or-subq}   FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({int-non-id-column-name}, ID)  SELECT {integer-col-or-subq}, {int-column-name}   FROM {table-ref-set}
insert-select-id-str    ::= SERT INTO {table-name-set} (ID, {string-column-name})      SELECT {int-column-name}, {string-col-or-subq}    FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({string-column-name}, ID)      SELECT {string-col-or-subq}, {int-column-name}    FROM {table-ref-set}
insert-select-id-time   ::= SERT INTO {table-name-set} (ID, {timestamp-column-name})   SELECT {int-column-name}, {timestamp-col-or-subq} FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({timestamp-column-name}, ID)   SELECT {timestamp-col-or-subq}, {int-column-name} FROM {table-ref-set}
insert-select-id-varbin ::= SERT INTO {table-name-set} (ID, {varbinary-column-name})   SELECT {int-column-name}, {varbinary-col-or-subq} FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({varbinary-column-name}, ID)   SELECT {varbinary-col-or-subq}, {int-column-name} FROM {table-ref-set}
insert-select-id-point  ::= SERT INTO {table-name-set} (ID, {point-column-name})       SELECT {int-column-name}, {point-col-or-subq}     FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({point-column-name}, ID)       SELECT {point-col-or-subq}, {int-column-name}     FROM {table-ref-set}
insert-select-id-poly   ::= SERT INTO {table-name-set} (ID, {polygon-column-name})     SELECT {int-column-name}, {polygon-col-or-subq}   FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({polygon-column-name}, ID)     SELECT {polygon-col-or-subq}, {int-column-name}   FROM {table-ref-set}
insert-select-id-json   ::= SERT INTO {table-name-set} (ID, {json-column-name})        SELECT {int-column-name}, {json-col-or-subq}      FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({json-column-name}, ID)        SELECT {json-col-or-subq}, {int-column-name}      FROM {table-ref-set}
insert-sel-id-str-ipv4  ::= SERT INTO {table-name-set} (ID, {string-ipv4-column-name}) SELECT {int-column-name}, {str-ipv4-col-or-subq}  FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({string-ipv4-column-name}, ID) SELECT {str-ipv4-col-or-subq}, {int-column-name}  FROM {table-ref-set}
insert-sel-id-str-ipv6  ::= SERT INTO {table-name-set} (ID, {string-ipv6-column-name}) SELECT {int-column-name}, {str-ipv6-col-or-subq}  FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({string-ipv6-column-name}, ID) SELECT {str-ipv6-col-or-subq}, {int-column-name}  FROM {table-ref-set}
insert-sel-id-varb-ipv4 ::= SERT INTO {table-name-set} (ID, {varbin-ipv4-column-name}) SELECT {int-column-name}, {varb-ipv4-col-or-subq} FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({varbin-ipv4-column-name}, ID) SELECT {varb-ipv4-col-or-subq}, {int-column-name} FROM {table-ref-set}
insert-sel-id-varb-ipv6 ::= SERT INTO {table-name-set} (ID, {varbin-ipv6-column-name}) SELECT {int-column-name}, {varb-ipv6-col-or-subq} FROM {table-ref-set} | \
                            SERT INTO {table-name-set} ({varbin-ipv6-column-name}, ID) SELECT {varb-ipv6-col-or-subq}, {int-column-name} FROM {table-ref-set}

numeric-col-or-subq     ::= {numeric-column-name}     9| {numeric-scalar-sub-q}
integer-col-or-subq     ::= {int-column-name}         9| {integer-scalar-sub-q}
byte-col-or-subq        ::= {byte-column-name}        9| {integer-scalar-sub-q}
string-col-or-subq      ::= {string-column-name}      9| {string-scalar-sub-q}
json-col-or-subq        ::= {json-column-name}        9| {json-scalar-sub-q}
timestamp-col-or-subq   ::= {timestamp-column-name}   9| {timestamp-scalar-sub-q}
varbinary-col-or-subq   ::= {varbinary-column-name}   9| {varbinary-scalar-sub-q}
point-col-or-subq       ::= {point-column-name}       9| {point-scalar-sub-q}
polygon-col-or-subq     ::= {polygon-column-name}     9| {polygon-scalar-sub-q}
str-ipv4-col-or-subq    ::= {string-ipv4-column-name} 9| {str-ipv4-scalar-sub-q}
str-ipv6-col-or-subq    ::= {string-ipv6-column-name} 9| {str-ipv6-scalar-sub-q}
varb-ipv4-col-or-subq   ::= {varbin-ipv4-column-name} 9| {varb-ipv4-scalar-sub-q}
varb-ipv6-col-or-subq   ::= {varbin-ipv6-column-name} 9| {varb-ipv6-scalar-sub-q}

insert-select-multiple  ::= SERT INTO {table-name-set} (ID, {numeric-non-id-col-name}, {string-column-name}, \
                            {timestamp-column-name}, {varbinary-column-name}, {point-column-name}, {polygon-column-name} ) \
                            SELECT {insert-select-mult-val} FROM {table-ref-set}
insert-select-all       ::= SERT INTO {table-name-set} [({every-column-name})] \
                            SELECT {insert-select-all-val}  FROM {table-ref-set}
insert-select-backward  ::= SERT INTO {table-name-set} ({every-col-name-backward}) \
                            SELECT {insert-select-back-val} FROM {table-ref-set}

insert-select-mult-val  ::= {insert-select-mult-val1} 4| {insert-select-mult-val2}
insert-select-mult-val1 ::= {int-column-name}, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                            {varbinary-column-name}, {point-column-name}, {polygon-column-name}
insert-select-mult-val2 ::= {int-column-name}, {numeric-col-or-subq}, {string-col-or-subq}, {timestamp-col-or-subq}, \
                            {varbinary-col-or-subq}, {point-col-or-subq}, {polygon-col-or-subq}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
insert-select-all-val   ::= {insert-select-all-val1} 4| {insert-select-all-val2}
insert-select-all-val1  ::= {int-column-name}, {byte-column-name}, {int-column-name}, {int-column-name}, \
                            {int-column-name}, {numeric-column-name}, {numeric-column-name}, \
                            {string-column-name}, {string-column-name}, {string-column-name}, \
                            {string-column-name}, {json-column-name}, \
                            {timestamp-column-name}, {varbinary-column-name}, {point-column-name}, {polygon-column-name}, \
                            {string-ipv4-column-name}, {string-ipv6-column-name}, {varbin-ipv4-column-name}, {varbin-ipv6-column-name}
insert-select-all-val2  ::= {int-column-name}, {byte-col-or-subq}, {integer-col-or-subq}, {integer-col-or-subq}, \
                            {integer-col-or-subq}, {numeric-col-or-subq}, {numeric-col-or-subq}, \
                            {string-col-or-subq}, {string-col-or-subq}, {string-col-or-subq}, \
                            {string-col-or-subq}, {json-col-or-subq}, \
                            {timestamp-col-or-subq}, {varbinary-col-or-subq}, {point-col-or-subq}, {polygon-col-or-subq}, \
                            {str-ipv4-col-or-subq}, {str-ipv6-col-or-subq}, {varb-ipv4-col-or-subq}, {varb-ipv6-col-or-subq}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
insert-select-back-val  ::= {insert-select-back-val1} 4| {insert-select-back-val2}
insert-select-back-val1 ::= {varbin-ipv6-column-name}, {varbin-ipv4-column-name}, {string-ipv6-column-name}, {string-ipv4-column-name}, \
                            {polygon-column-name}, {point-column-name}, {varbinary-column-name}, {timestamp-column-name}, \
                            {json-column-name}, {string-column-name}, {string-column-name}, \
                            {string-column-name}, {string-column-name}, \
                            {numeric-column-name}, {numeric-column-name}, {int-column-name}, \
                            {int-column-name}, {int-column-name}, {byte-column-name}, {int-column-name}
insert-select-back-val2 ::= {varb-ipv6-col-or-subq}, {varb-ipv4-col-or-subq}, {str-ipv6-col-or-subq}, {str-ipv4-col-or-subq}, \
                            {polygon-col-or-subq}, {point-col-or-subq}, {varbinary-col-or-subq}, {timestamp-col-or-subq}, \
                            {json-col-or-subq}, {string-col-or-subq}, {string-col-or-subq}, {string-col-or-subq}, {string-col-or-subq}, \
                            {numeric-col-or-subq}, {numeric-col-or-subq}, {integer-col-or-subq}, {integer-col-or-subq}, \
                            {integer-col-or-subq}, {byte-col-or-subq}, {int-column-name}

################################################################################
# Grammar rules for an UPSERT statement (almost identical to INSERT):
################################################################################
#
upsert-statement        ::= {upsert-values-statement} | {upsert-select-statement}

# The "9" before the "|" makes the "simple-upsert-values" or "simple-upsert-select"
# option 9 times as likely as the other option, making simple, valid statements
# more likely
upsert-values-statement ::= {simple-upsert-values} 9| {upsert-clause} VALUES ({values-list})
upsert-select-statement ::= {simple-upsert-select} 9| {upsert-clause} {select-statement}

# Putting "({column-list})" in more than one set of brackets makes it less likely
upsert-clause           ::= UPSERT INTO {table-name} [[({column-list})]]

simple-upsert-values    ::= UP{in-or-up-sert-values}
simple-upsert-select    ::= UP{in-or-up-sert-select}

################################################################################
# Grammar rules for an UPDATE statement:
################################################################################
#
update-statement        ::= UPDATE {table-name-or-alias-set} SET {column-updates} [{where-clause}] 4| \
                            {corltd-update-statement}

column-updates          ::= {column-update} [, {column-updates}]
column-update           ::= {valid-column-update} 99| \
                            {column-name}             = {value-expression}
valid-column-update     ::= {numeric-column-name}     = {numeric-expression}  7| \
                            {string-column-name}      = {string-expression}   4| \
                            {timestamp-column-name}   = {timestamp-expression} | \
                            {varbinary-column-name}   = {varbinary-expression} | \
                            {point-column-name}       = {point-expression}     | \
                            {polygon-column-name}     = {polygon-expression}   | \
                            {string-ipv4-column-name} = {string-ipv4-expression} | \
                            {string-ipv6-column-name} = {string-ipv6-expression} | \
                            {varbin-ipv4-column-name} = {varbin-ipv4-expression} | \
                            {varbin-ipv6-column-name} = {varbin-ipv6-expression}

# UPDATE statements making use of a correlated column, often in a sub-query,
# in either the SET or the WHERE clause, or both
corltd-update-statement ::= UPDATE {table-name} [AS ]{t0}   SET {column-updates} WHERE {correlated-t0-bool-expr}  | \
                            UPDATE {table-name-or-alias-t1} SET {column-updates} WHERE {correlated-t1-bool-expr}  | \
                            UPDATE {table-name} [AS ]{t0}   SET {corltd-t0-column-updates} [{where-clause}] | \
                            UPDATE {table-name-or-alias-t1} SET {corltd-t1-column-updates} [{where-clause}] | \
                            UPDATE {table-name} [AS ]{t0}   SET {corltd-t0-column-updates} WHERE {correlated-t0-bool-expr} | \
                            UPDATE {table-name-or-alias-t1} SET {corltd-t1-column-updates} WHERE {correlated-t1-bool-expr}

corltd-t0-column-updates::= {corltd-t0-column-update} [, {corltd-t0-column-updates}]
corltd-t0-column-update ::= {column-update} 5| \
                            {numeric-column-name}   = {corltd-t0-numeric-expr}  7| \
                            {string-column-name}    = {corltd-t0-string-expr}   4| \
                            {timestamp-column-name} = {corltd-t0-timestamp-expr} | \
                            {varbinary-column-name} = {corltd-t0-varbinary-expr} | \
                            {point-column-name}     = {corltd-t0-point-expr}     | \
                            {polygon-column-name}   = {corltd-t0-polygon-expr}

corltd-t1-column-updates::= {corltd-t1-column-update} [, {corltd-t1-column-updates}]
corltd-t1-column-update ::= {column-update} 5| \
                            {numeric-column-name}   = {corltd-t1-numeric-expr}  7| \
                            {string-column-name}    = {corltd-t1-string-expr}   4| \
                            {timestamp-column-name} = {corltd-t1-timestamp-expr} | \
                            {varbinary-column-name} = {corltd-t1-varbinary-expr} | \
                            {point-column-name}     = {corltd-t1-point-expr}     | \
                            {polygon-column-name}   = {corltd-t1-polygon-expr}

################################################################################
# Grammar rules for a DELETE (or TRUNCATE) statement:
################################################################################
#
# The "19" before the "|" makes the "basic-delete-statement" option much more
# likely than the "truncate-statement" option, since we don't want to truncate
# (delete all data from) a table too often
#
delete-statement        ::= {basic-delete-statement} 19| {truncate-statement}

basic-delete-statement  ::= DELETE FROM {table-name-set}[ {where-clause}][ {sort-clause}] 4| \
                            DELETE FROM {table-name:t1} WHERE {correlated-t1-bool-expr}

truncate-statement      ::= TRUNCATE TABLE {table-name}

################################################################################
# Grammar rules for a MIGRATE statement:
################################################################################
#
migrate-statement       ::= MIGRATE FROM {migrate-table-name-set}  {where-not-migrating}[     {sort-clause}] 4| \
                            MIGRATE FROM {migrate-table-name-set}[ {where-not-migrating}][    {sort-clause}]  | \
                            MIGRATE FROM {migrate-table-name:t1}   {where-corl-t1-not-migr}[  {sort-clause}] 4| \
                            MIGRATE FROM {migrate-table-name:t1}[  {where-corl-t1-not-migr}][ {sort-clause}]

# Test MIGRATE with a NOT MIGRATING() where clause most of the time,
# but not always
where-not-migrating     ::= WHERE {not-migrating-where-cls} 3| \
                            [WHERE {not-migrating-where-cls}]
not-migrating-where-cls ::= {not-migrating} {probably-and} {boolean-expression}   4| \
                            {boolean-expression} {probably-and} {not-migrating}      \
                                          [[{probably-and} {boolean-expression}]] 5| \
                            {boolean-expression}
not-migrating           ::= NOT MIGRATING[()] 8| MIGRATING[()] | {boolean-expression}
probably-and            ::= AND 19| OR

where-corl-t1-not-migr  ::= WHERE {not-migrating} AND {correlated-t1-bool-expr} | \
                            WHERE {correlated-t1-bool-expr} AND {not-migrating}

################################################################################
# Grammar rules for a Common Table Expression (CTE) statement, i.e. using a
# WITH clause, with or without RECURSIVE:
################################################################################
#
cte-statement           ::= {basic-cte-statement} | {recursive-cte-statement}

########################################
# Basic (non-recursive) CTEs
#
basic-cte-statement     ::= WITH {basic-cte-query}\
                            {empty:depth}{empty:1depth}{empty:agdepth}

# This is used above to replace certain things, mainly related to the DEPTH
# column, that are needed by Recursive CTEs, but not by "basic" (non-recursive)
# CTEs; so for those, they are replaced with an empty string
empty                   ::=

basic-cte-query         ::= {basic-cte-int} 4| {basic-cte-num} 2| {basic-cte-str} 4| \
                            {basic-cte-time} | {basic-cte-varbin} | {basic-cte-point} | {basic-cte-polygon} | \
                            {basic-cte-num-str} | {basic-cte-str-num} | {basic-cte-3-int} | {basic-cte-3-str} | \
                            {basic-cte-9-int} | {basic-cte-9-str} | {basic-cte-9-mixed}

basic-cte-int           ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-int} ) \
                            {final-query-1num}
basic-cte-num           ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-num} ) \
                            {final-query-1num}
basic-cte-str           ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-str} ) \
                            {final-query-1non-num}
basic-cte-time          ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-time} ) \
                            {final-query-1non-num}
basic-cte-varbin        ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-varbin} ) \
                            {final-query-1non-num}
basic-cte-point         ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-point} ) \
                            {final-query-1non-num}
basic-cte-polygon       ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-polygon} ) \
                            {final-query-1non-num}
basic-cte-num-str       ::= cte{optional-2-cte-cols} AS (\
                            {basic-query-num-str} ) \
                            {final-query-1num-1non}
basic-cte-str-num       ::= cte{optional-2-cte-cols} AS (\
                            {basic-query-str-num} ) \
                            {final-query-1non-1num}
basic-cte-3-int         ::= cte{optional-3-cte-cols} AS (\
                            {basic-query-3-int} ) \
                            {final-query-3num}
basic-cte-3-str         ::= cte{optional-3-cte-cols} AS (\
                            {basic-query-3-str} ) \
                            {final-query-3non-num}
basic-cte-9-int         ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-int} ) \
                            {final-query-9num}
basic-cte-9-str         ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-str} ) \
                            {final-query-9non-num}
basic-cte-9-mixed       ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-mixed} ) \
                            {final-query-9-mixed}

########################################
# Grammar definitions used for both
# kinds of CTE: "basic" (non-recursive,
# above) and Recursive (below) 
#

# Note: VALUES version not currently supported by VoltDB, so make this rare
# TODO: change per Chris review: (add GROUP BY; also ORDER BY ???)
basic-query-int         ::= SELECT {int-expression}[[ {cte-col1-alias}]]        {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({int-rarely-null-value} {one-as-depth})
basic-query-num         ::= SELECT {numeric-expression}[[ {cte-col1-alias}]]    {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({num-rarely-null-value} {one-as-depth})
basic-query-str         ::= SELECT {cte-string-expression}[[ {cte-col1-alias}]] {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({str-rarely-null-value} {one-as-depth})
basic-query-time        ::= SELECT {timestamp-expression}[[ {cte-col1-alias}]]  {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({time-rarely-null-value} {one-as-depth})
basic-query-varbin      ::= SELECT {varbinary-expression}[[ {cte-col1-alias}]]  {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({varbin-rarely-null-value} {one-as-depth})
basic-query-point       ::= SELECT {point-expression}[[ {cte-col1-alias}]]      {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({point-rarely-null-value} {one-as-depth})
basic-query-polygon     ::= SELECT {polygon-expression}[[ {cte-col1-alias}]]    {one-as-depth} FROM {table-refs} [{where-clause}] 199| \
                            VALUES ({poly-rarely-null-value} {one-as-depth})
basic-query-num-str     ::= SELECT {numeric-expression},                  {cte-string-expression}                  {one-as-depth} FROM {table-refs} [{where-clause}] 150| \
                            SELECT {numeric-expression} {cte-col1-alias}, {cte-string-expression} {cte-col2-alias} {one-as-depth} FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({num-rarely-null-value}, {str-rarely-null-value} {one-as-depth})
basic-query-str-num     ::= SELECT {cte-string-expression},                  {numeric-expression}                  {one-as-depth} FROM {table-refs} [{where-clause}] 150| \
                            SELECT {cte-string-expression} {cte-col1-alias}, {numeric-expression} {cte-col2-alias} {one-as-depth} FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({str-rarely-null-value}, {num-rarely-null-value} {one-as-depth})
basic-query-3-int       ::= SELECT {int-expression},                  {int-expression},                  {int-expression} {one-as-depth} \
                            FROM {table-refs} [{where-clause}] 150| \
                            SELECT {int-expression} {cte-col1-alias}, {int-expression} {cte-col2-alias}, {int-expression} {cte-col3-alias} {one-as-depth} \
                            FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({int-rarely-null-value}, {int-rarely-null-value}, {int-rarely-null-value} {one-as-depth})
basic-query-3-str       ::= SELECT {cte-string-expression},                  {cte-string-expression},                  {cte-string-expression} {one-as-depth} \
                            FROM {table-refs} [{where-clause}] 150| \
                            SELECT {cte-string-expression} {cte-col1-alias}, {cte-string-expression} {cte-col2-alias}, {cte-string-expression} {cte-col3-alias} {one-as-depth} \
                            FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({str-rarely-null-value}, {str-rarely-null-value}, {str-rarely-null-value} {one-as-depth})
basic-query-9-int       ::= SELECT {int-expression}, {int-expression}, {int-expression}, \
                                   {int-expression}, {int-expression}, {int-expression}, \
                                   {int-expression}, {int-expression}, {int-expression} {one-as-depth} \
                            FROM {table-refs} [{where-clause}] 150| \
                            SELECT {int-expression} {cte-col1-alias}, {int-expression} {cte-col2-alias}, {int-expression} {cte-col3-alias}, \
                                   {int-expression} {cte-col4-alias}, {int-expression} {cte-col5-alias}, {int-expression} {cte-col6-alias}, \
                                   {int-expression} {cte-col7-alias}, {int-expression} {cte-col8-alias}, {int-expression} {cte-col9-alias} {one-as-depth} \
                            FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({int-rarely-null-value}, {int-rarely-null-value}, {int-rarely-null-value}, \
                                    {int-rarely-null-value}, {int-rarely-null-value}, {int-rarely-null-value}, \
                                    {int-rarely-null-value}, {int-rarely-null-value}, {int-rarely-null-value} {one-as-depth})
basic-query-9-str       ::= SELECT {cte-string-expression}, {cte-string-expression}, {cte-string-expression}, \
                                   {cte-string-expression}, {cte-string-expression}, {cte-string-expression}, \
                                   {cte-string-expression}, {cte-string-expression}, {cte-string-expression} {one-as-depth} \
                            FROM {table-refs} [{where-clause}] 150| \
                            SELECT {cte-string-expression} {cte-col1-alias}, {cte-string-expression} {cte-col2-alias}, {cte-string-expression} {cte-col3-alias}, \
                                   {cte-string-expression} {cte-col4-alias}, {cte-string-expression} {cte-col5-alias}, {cte-string-expression} {cte-col6-alias}, \
                                   {cte-string-expression} {cte-col7-alias}, {cte-string-expression} {cte-col8-alias}, {cte-string-expression} {cte-col9-alias}  \
                                   {one-as-depth} \
                            FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({str-rarely-null-value}, {str-rarely-null-value}, {str-rarely-null-value}, \
                                    {str-rarely-null-value}, {str-rarely-null-value}, {str-rarely-null-value}, \
                                    {str-rarely-null-value}, {str-rarely-null-value}, {str-rarely-null-value} {one-as-depth})
basic-query-9-mixed     ::= SELECT {int-expression}, {cte-string-expression}, {numeric-expression}, \
                                   {int-expression}, {cte-string-expression}, {varbinary-expression}, \
                                   {int-expression}, {cte-string-expression}, {timestamp-expression} {one-as-depth} \
                            FROM {table-refs} [{where-clause}] 150| \
                            SELECT {int-expression} {cte-col1-alias}, {cte-string-expression} {cte-col2-alias}, {numeric-expression}   {cte-col3-alias}, \
                                   {int-expression} {cte-col4-alias}, {cte-string-expression} {cte-col5-alias}, {varbinary-expression} {cte-col6-alias}, \
                                   {int-expression} {cte-col7-alias}, {cte-string-expression} {cte-col8-alias}, {timestamp-expression} {cte-col9-alias}  \
                                   {one-as-depth} \
                            FROM {table-refs} [{where-clause}]  49| \
                            VALUES ({int-rarely-null-value}, {str-rarely-null-value}, {num-rarely-null-value}, \
                                    {int-rarely-null-value}, {str-rarely-null-value}, {varbin-rarely-null-value}, \
                                    {int-rarely-null-value}, {str-rarely-null-value}, {time-rarely-null-value} {one-as-depth})

cte-string-expression   ::= {simple-cte-string-expr} 49| {string-scalar-sub-q}
simple-cte-string-expr  ::= {table-ref}.{cte-string-column-name} 6| {cte-string-column-name} 2| \
                            {string-value} | {string-function-expr}
cte-string-column-name  ::= VCHAR 9| {any-string-column-name}

cte-col1                ::= CTE_C1
cte-col2                ::= CTE_C2
cte-col3                ::= CTE_C3
cte-col4                ::= CTE_C4
cte-col5                ::= CTE_C5
cte-col6                ::= CTE_C6
cte-col7                ::= CTE_C7
cte-col8                ::= CTE_C8
cte-col9                ::= CTE_C9

ctec1-9                 ::= {cte-col1:ctec1} | {cte-col2:ctec2} | {cte-col3:ctec3} | \
                            {cte-col4:ctec4} | {cte-col5:ctec5} | {cte-col6:ctec6} | \
                            {cte-col7:ctec7} | {cte-col8:ctec8} | {cte-col9:ctec9}

cte-col-alias1          ::= CA1
cte-col-alias2          ::= CA2
cte-col-alias3          ::= CA3
cte-col-alias4          ::= CA4
cte-col-alias5          ::= CA5
cte-col-alias6          ::= CA6
cte-col-alias7          ::= CA7
cte-col-alias8          ::= CA8
cte-col-alias9          ::= CA9

cte-col1-alias          ::= [AS ]{cte-col-alias1:ctec1}
cte-col2-alias          ::= [AS ]{cte-col-alias2:ctec2}
cte-col3-alias          ::= [AS ]{cte-col-alias3:ctec3}
cte-col4-alias          ::= [AS ]{cte-col-alias4:ctec4}
cte-col5-alias          ::= [AS ]{cte-col-alias5:ctec5}
cte-col6-alias          ::= [AS ]{cte-col-alias6:ctec6}
cte-col7-alias          ::= [AS ]{cte-col-alias7:ctec7}
cte-col8-alias          ::= [AS ]{cte-col-alias8:ctec8}
cte-col9-alias          ::= [AS ]{cte-col-alias9:ctec9}

# Note: DEPTH "column" added to avoid infinite loops, per ENG-13586 (but only
# for Recursive CTEs, not needed for "basic" non-recursive)
optional-1-cte-col      ::=  ({cte-col1:ctec1}  {depth}) 8| [({cte-col1:ctec1} {depth})]
optional-2-cte-cols     ::=  ({cte-col1:ctec1}, {cte-col2:ctec2}  {depth}) 8| \
                            [({cte-col1:ctec1}, {cte-col2:ctec2}  {depth})]
optional-3-cte-cols     ::=  ({cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col3:ctec3} {depth}) 8| \
                            [({cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col3:ctec3} {depth})]
optional-9-cte-cols     ::=  ({cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col3:ctec3}, \
                              {cte-col4:ctec4}, {cte-col5:ctec5}, {cte-col6:ctec6}, \
                              {cte-col7:ctec7}, {cte-col8:ctec8}, {cte-col9:ctec9} {depth}) 8| \
                            [({cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                              {cte-col4:ctec4}, {cte-col5:ctec5}, {cte-col6:ctec6}, \
                              {cte-col7:ctec7}, {cte-col8:ctec8}, {cte-col9:ctec9} {depth})]

# Note: this level of indirection using ":depth", ":1depth", or ":agdepth"
# allows recursive CTEs to set these definitions to appropriate values
# related to DEPTH (which is used to prevent infinite loops), while "basic"
# (non-recursive) CTEs can remove these terms, by replacing them with an
# empty string
depth                   ::= {depth2:depth}
depth2                  ::= , DEPTH
one-as-depth            ::= {one-as-depth2:1depth}
one-as-depth2           ::= , 1[[[ AS] DEPTH]]
aggregate-depth-funcs   ::= {aggregate-depth-funcs2:agdepth}
aggregate-depth-funcs2  ::=  , MIN(DEPTH) MND, MAX(DEPTH) MXD, COUNT(DEPTH) CTD, SUM(DEPTH) SMD, AVG(DEPTH) AVD 2| \
                            [, MIN(DEPTH) MND, MAX(DEPTH) MXD, COUNT(DEPTH) CTD, SUM(DEPTH) SMD, AVG(DEPTH) AVD] | \
                            [, MIN(DEPTH) MND][, MAX(DEPTH) MXD][, COUNT(DEPTH) CTD][, SUM(DEPTH) SMD][, AVG(DEPTH) AVD]

aggregate-func-ctec1    ::= {aggregate-function}({:ctec1}) 18| \
                            COUNT(DISTINCT {:ctec1})         | \
                            COUNT(*)
aggregate-func-ctec2    ::= {aggregate-function}({:ctec2}) 18| \
                            COUNT(DISTINCT {:ctec2})         | \
                            COUNT(*)
aggregate-func-ctec3    ::= {aggregate-function}({:ctec3}) 18| \
                            COUNT(DISTINCT {:ctec3})         | \
                            COUNT(*)

# TODO: lots more options could be used here
final-query-1num        ::= SELECT {star} FROM cte | \
                            SELECT {aggregate-func-ctec1}            AG1 {aggregate-depth-funcs} FROM cte
final-query-1non-num    ::= SELECT {star} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec1}) AG1 {aggregate-depth-funcs} FROM cte
final-query-1num-1non   ::= SELECT {star} FROM cte | \
                            SELECT {aggregate-func-ctec1}            AG1[, {non-num-arg-aggr-func}({:ctec1}) AG2]\
                                {aggregate-depth-funcs} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec1}) AG2[,            {aggregate-func-ctec1} AG1]\
                                {aggregate-depth-funcs} FROM cte
final-query-1non-1num   ::= SELECT {star} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec1}) AG1[,            {aggregate-func-ctec2} AG2]\
                                {aggregate-depth-funcs} FROM cte | \
                            SELECT           {aggregate-func-ctec2}  AG2[, {non-num-arg-aggr-func}({:ctec1}) AG1]\
                                {aggregate-depth-funcs} FROM cte
final-query-3num        ::= SELECT {star} FROM cte | \
                            SELECT {aggregate-func-ctec1} AG1[, {aggregate-func-ctec2} AG2]\
                                [, {aggregate-func-ctec3} AG3] {aggregate-depth-funcs} FROM cte | \
                            SELECT {aggregate-func-ctec2} AG2[, {aggregate-func-ctec1} AG1]\
                                [, {aggregate-func-ctec3} AG3] {aggregate-depth-funcs} FROM cte | \
                            SELECT {aggregate-func-ctec3} AG3[, {aggregate-func-ctec2} AG2]\
                                [, {aggregate-func-ctec1} AG1] {aggregate-depth-funcs} FROM cte
final-query-3non-num    ::= SELECT {star} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec1}) AG1[, {non-num-arg-aggr-func}({:ctec2}) AG2]\
                                [, {non-num-arg-aggr-func}({:ctec3}) AG3]   {aggregate-depth-funcs} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec2}) AG2[, {non-num-arg-aggr-func}({:ctec1}) AG1]\
                                [, {non-num-arg-aggr-func}({:ctec3}) AG3]   {aggregate-depth-funcs} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec3}) AG3[, {non-num-arg-aggr-func}({:ctec2}) AG2]\
                                [, {non-num-arg-aggr-func}({:ctec1}) AG1]   {aggregate-depth-funcs} FROM cte
final-query-9num        ::= SELECT {star} FROM cte | \
                            SELECT {aggregate-function}({ctec1-9}) AG1[, {aggregate-function}({ctec1-9}) AG2][, {aggregate-function}({ctec1-9}) AG3] \
                                [, {aggregate-function}({ctec1-9}) AG4,  {aggregate-function}({ctec1-9}) AG5,   {aggregate-function}({ctec1-9}) AG6] \
                                [, {aggregate-function}({ctec1-9}) AG7,  {aggregate-function}({ctec1-9}) AG8,   {aggregate-function}({ctec1-9}) AG9] \
                            {aggregate-depth-funcs} FROM cte
final-query-9non-num    ::= SELECT {star} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({ctec1-9}) AG1[, {non-num-arg-aggr-func}({ctec1-9}) AG2][, {non-num-arg-aggr-func}({ctec1-9}) AG3] \
                                [, {non-num-arg-aggr-func}({ctec1-9}) AG4,  {non-num-arg-aggr-func}({ctec1-9}) AG5,   {non-num-arg-aggr-func}({ctec1-9}) AG6] \
                                [, {non-num-arg-aggr-func}({ctec1-9}) AG7,  {non-num-arg-aggr-func}({ctec1-9}) AG8,   {non-num-arg-aggr-func}({ctec1-9}) AG9] \
                            {aggregate-depth-funcs} FROM cte
final-query-9-mixed     ::= SELECT {star} FROM cte | \
                            SELECT {aggregate-func-ctec1}         AG1[, {non-num-arg-aggr-func}({:ctec2}) AG2][,         {aggregate-func-ctec3}  AG3] \
                                [, {aggregate-function}({:ctec4}) AG4,  {non-num-arg-aggr-func}({:ctec5}) AG5, {non-num-arg-aggr-func}({:ctec6}) AG6] \
                                [, {aggregate-function}({:ctec7}) AG7,  {non-num-arg-aggr-func}({:ctec8}) AG8, {non-num-arg-aggr-func}({:ctec9}) AG9] \
                            {aggregate-depth-funcs} FROM cte | \
                            SELECT {non-num-arg-aggr-func}({:ctec9}) AG9[, {non-num-arg-aggr-func}({:ctec8}) AG8][, {aggregate-function}({:ctec7}) AG7] \
                                [, {non-num-arg-aggr-func}({:ctec6}) AG6,  {non-num-arg-aggr-func}({:ctec5}) AG5,   {aggregate-function}({:ctec4}) AG4] \
                                [,           {aggregate-func-ctec3}  AG3,  {non-num-arg-aggr-func}({:ctec2}) AG2,   {aggregate-func-ctec1}         AG1] \
                            {aggregate-depth-funcs} FROM cte

########################################
# Recursive CTEs
#
recursive-cte-statement ::= WITH RECURSIVE {recursive-cte-query}

recursive-cte-query     ::= {rec-cte-int} 4| {rec-cte-num} 2| {rec-cte-str} 4| \
                            {rec-cte-time} | {rec-cte-varbin} | {rec-cte-point} | {rec-cte-polygon} | \
                            {rec-cte-num-str} | {rec-cte-str-num} | {rec-cte-3-int} | {rec-cte-3-str} | \
                            {rec-cte-9-int} | {rec-cte-9-str} | {rec-cte-9-mixed}

rec-cte-int             ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-int} \
                            {union-all} \
                            {recursive-query-int} ) \
                            {final-query-1num}
rec-cte-num             ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-num} \
                            {union-all} \
                            {recursive-query-num} ) \
                            {final-query-1num}
rec-cte-str             ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-str} \
                            {union-all} \
                            {recursive-query-str} ) \
                            {final-query-1non-num}
rec-cte-time            ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-time} \
                            {union-all} \
                            {recursive-query-time} ) \
                            {final-query-1non-num}
rec-cte-varbin          ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-varbin} \
                            {union-all} \
                            {recursive-query-varbin} ) \
                            {final-query-1non-num}
rec-cte-point           ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-point} \
                            {union-all} \
                            {recursive-query-point} ) \
                            {final-query-1non-num}
rec-cte-polygon         ::= cte{optional-1-cte-col}  AS (\
                            {basic-query-polygon} \
                            {union-all} \
                            {recursive-query-polygon} ) \
                            {final-query-1non-num}
rec-cte-num-str         ::= cte{optional-2-cte-cols} AS (\
                            {basic-query-num-str} \
                            {union-all} \
                            {recursive-query-num-str} ) \
                            {final-query-1num-1non}
rec-cte-str-num         ::= cte{optional-2-cte-cols} AS (\
                            {basic-query-str-num} \
                            {union-all} \
                            {recursive-query-str-num} ) \
                            {final-query-1non-1num}
rec-cte-3-int           ::= cte{optional-3-cte-cols} AS (\
                            {basic-query-3-int} \
                            {union-all} \
                            {recursive-query-3-int} ) \
                            {final-query-3num}
rec-cte-3-str           ::= cte{optional-3-cte-cols} AS (\
                            {basic-query-3-str} \
                            {union-all} \
                            {recursive-query-3-str} ) \
                            {final-query-3non-num}
rec-cte-9-int           ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-int} \
                            {union-all} \
                            {recursive-query-9-int} ) \
                            {final-query-9num}
rec-cte-9-str           ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-str} \
                            {union-all} \
                            {recursive-query-9-str} ) \
                            {final-query-9non-num}
rec-cte-9-mixed         ::= cte{optional-9-cte-cols} AS (\
                            {basic-query-9-mixed} \
                            {union-all} \
                            {recursive-query-9-mixed} ) \
                            {final-query-9-mixed}

# Note: version using UNION without ALL not currently supported by VoltDB,
# so make that rare
union-all               ::= UNION ALL 99| UNION [ALL]

# Used to avoid infinite loops in the recursive queries below
max-depth               ::= 5 | {digit-0-to-5} | {digit}

# TODO: lots more options here (for the WHERE clause)
# TODO: change per Chris review: (add GROUP BY; also ORDER BY ???)
recursive-query-int     ::= SELECT {recursive-clause-int1},    DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {int-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-num     ::= SELECT {recursive-clause-num1},    DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {num-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-str     ::= SELECT {recursive-clause-str1},    DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {str-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-time    ::= SELECT {recursive-clause-time1},   DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {time-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-varbin  ::= SELECT {recursive-clause-varbin1}, DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {varbin-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-point   ::= SELECT {recursive-clause-point1},  DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {point-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-polygon ::= SELECT {recursive-clause-poly1},   DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {poly-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-num-str ::= SELECT {recursive-clause-num1}, {cte-col2:ctec2}, DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {num-rarely-null-value} \
                              AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-str2}, DEPTH + 1 FROM cte \
                            WHERE {cte-col2:ctec2} {comparison-operator} {str-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-str-num ::= SELECT {recursive-clause-str1}, {cte-col2:ctec2}, DEPTH + 1 FROM cte \
                            WHERE {cte-col1:ctec1} {comparison-operator} {str-rarely-null-value} \
                              AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-num2}, DEPTH + 1 FROM cte \
                            WHERE {cte-col2:ctec2} {comparison-operator} {num-rarely-null-value} \
                              AND DEPTH < {max-depth}
recursive-query-3-int   ::= SELECT {recursive-clause-int1}, {cte-col2:ctec2}, {cte-col2:ctec3}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec1} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-int2}, {cte-col2:ctec3}, DEPTH + 1 \
                            FROM cte WHERE {int-rarely-null-value} {comparison-operator} {cte-col2:ctec2} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {recursive-clause-int3}, DEPTH + 1 \
                            FROM cte WHERE {cte-col2:ctec3} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth}
recursive-query-3-str   ::= SELECT {recursive-clause-str1}, {cte-col2:ctec2}, {cte-col2:ctec3}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec1} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-str2}, {cte-col2:ctec3}, DEPTH + 1 \
                            FROM cte WHERE {str-rarely-null-value} {comparison-operator} {cte-col2:ctec2} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {recursive-clause-str3}, DEPTH + 1 \
                            FROM cte WHERE {cte-col2:ctec3} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth}

recursive-query-9-int   ::= SELECT {recursive-clause-int1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec1} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-int2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec2} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {recursive-clause-int3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec3} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {recursive-clause-int4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec4} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {recursive-clause-int5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec5} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {recursive-clause-int6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec6} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {recursive-clause-int7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec7} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {recursive-clause-int8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec8} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {recursive-clause-int9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec9} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth}

recursive-query-9-str   ::= SELECT {recursive-clause-str1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec1} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-str2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec2} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {recursive-clause-str3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec3} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {recursive-clause-str4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec4} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {recursive-clause-str5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec5} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {recursive-clause-str6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec6} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {recursive-clause-str7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec7} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {recursive-clause-str8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec8} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {recursive-clause-str9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec9} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth}

recursive-query-9-mixed ::= SELECT {recursive-clause-int1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec1} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {recursive-clause-str2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec2} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {recursive-clause-num3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec3} {comparison-operator} {num-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {recursive-clause-int4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec4} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {recursive-clause-str5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec5} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {recursive-clause-varbin6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec6} {comparison-operator} {varbin-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {recursive-clause-int7}, {cte-col2:ctec8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec7} {comparison-operator} {int-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {recursive-clause-str8}, {cte-col2:ctec9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec8} {comparison-operator} {str-rarely-null-value} \
                                        AND DEPTH < {max-depth} | \
                            SELECT {cte-col1:ctec1}, {cte-col2:ctec2}, {cte-col2:ctec3}, \
                                   {cte-col1:ctec4}, {cte-col2:ctec5}, {cte-col2:ctec6}, \
                                   {cte-col1:ctec7}, {cte-col2:ctec8}, {recursive-clause-time9}, DEPTH + 1 \
                            FROM cte WHERE {cte-col1:ctec9} {comparison-operator} {time-rarely-null-value} \
                                        AND DEPTH < {max-depth}

# TODO: could use functions here, etc.
recursive-clause-int1   ::= {cte-col1:ctec1} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col1:ctec3}
recursive-clause-int2   ::= {cte-col2:ctec2} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col2:ctec2}
recursive-clause-int3   ::= {cte-col3:ctec3} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col3:ctec3}
recursive-clause-int4   ::= {cte-col4:ctec4} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col4:ctec3}
recursive-clause-int5   ::= {cte-col5:ctec5} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col5:ctec3}
recursive-clause-int6   ::= {cte-col6:ctec6} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col6:ctec3}
recursive-clause-int7   ::= {cte-col7:ctec7} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col7:ctec3}
recursive-clause-int8   ::= {cte-col8:ctec8} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col8:ctec3}
recursive-clause-int9   ::= {cte-col9:ctec9} {math-operator} {int-rarely-null-value} | \
                            {int-rarely-null-value} {math-operator} {cte-col9:ctec3}
recursive-clause-num1   ::= {cte-col1:ctec1} {math-operator} {num-rarely-null-value} | \
                            {num-rarely-null-value} {math-operator} {cte-col1:ctec1}
recursive-clause-num2   ::= {cte-col2:ctec2} {math-operator} {num-rarely-null-value} | \
                            {num-rarely-null-value} {math-operator} {cte-col2:ctec2}
recursive-clause-num3   ::= {cte-col3:ctec3} {math-operator} {num-rarely-null-value} | \
                            {num-rarely-null-value} {math-operator} {cte-col3:ctec3}
recursive-clause-str1   ::= {cte-col1:ctec1} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col1:ctec1}
recursive-clause-str2   ::= {cte-col2:ctec2} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col2:ctec2}
recursive-clause-str3   ::= {cte-col3:ctec3} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col3:ctec3}
recursive-clause-str4   ::= {cte-col4:ctec4} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col4:ctec4}
recursive-clause-str5   ::= {cte-col5:ctec5} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col5:ctec5}
recursive-clause-str6   ::= {cte-col6:ctec6} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col6:ctec6}
recursive-clause-str7   ::= {cte-col7:ctec7} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col7:ctec7}
recursive-clause-str8   ::= {cte-col8:ctec8} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col8:ctec8}
recursive-clause-str9   ::= {cte-col9:ctec9} {string-operator} {str-rarely-null-value} | \
                            {str-rarely-null-value} {string-operator} {cte-col9:ctec9}
recursive-clause-time1  ::= DATEADD(YEAR, {int-rarely-null-value}, {cte-col1:ctec1})
recursive-clause-time9  ::= DATEADD(YEAR, {int-rarely-null-value}, {cte-col9:ctec9})
recursive-clause-varbin1::= add2Varbinary({cte-col1:ctec1}, {varbin-rarely-null-value}) | \
                            add2Varbinary({varbin-rarely-null-value}, {cte-col1:ctec1})
recursive-clause-varbin6::= add2Varbinary({cte-col6:ctec6}, {varbin-rarely-null-value}) | \
                            add2Varbinary({varbin-rarely-null-value}, {cte-col6:ctec6})
recursive-clause-point1 ::= add2GeographyPoint({cte-col1:ctec1}, {point-rarely-null-value}) | \
                            add2GeographyPoint({point-rarely-null-value}, {cte-col1:ctec1})
recursive-clause-poly1  ::= addGeographyPointToGeography({cte-col1:ctec1}, {point-rarely-null-value})

################################################################################
# Grammar rules for special non-standard statements that can be used in sqlcmd
# (and therefore should be tested), even though they are not part of standard
# SQL. The most important such statements are the ones that 'exec' a (System,
# Default, or User-defined) Stored Procedure; but you can also 'explain' a SQL
# statement, procedure, or view; or 'show' a list of tables, classes,
# procedures, or functions.
################################################################################
#
sqlcmd-statement        ::= {exec-stored-proc} 89| {explain-statement} 10| \
                            {show-statement}

# Note: both 'exec' and 'show' have two spaces after them; this is a kludge
# so that all 'exec' statements, and similarly all 'show' statements, will be
# classified as the same type of statement, since the first 6 characters are
# used to determine the SQL statment type.
exec-stored-proc        ::= exec  {stored-proc}
stored-proc             ::= {user-stored-proc} 3| {default-stored-proc} 2| {system-stored-proc}

show-statement          ::= show  {show-items}
legit-show-items        ::= tables 2| classes 2| functions 2| proc | procedures
show-items              ::= {legit-show-items} 199| NONEXISTENT

explain-statement       ::= {explain-sql-statement} | {explainproc-statement} | {explainview-statement}
explain-sql-statement   ::= explain {sql-statement}
explainproc-statement   ::= explainproc {stored-proc-name}
explainview-statement   ::= explainview {view-name}

stored-proc-name        ::= {user-proc-name} 5| {default-proc-name} 4| {system-proc-name}

################################################################################
# System Stored Procedures
#
system-proc-name        ::= @AdHocLarge | @Explain | @ExplainProc | @ExplainView | \
                            @GetPartitionKeys | @ShapshotDelete | @ShapshotRestore | \
                            @ShapshotSave | @ShapshotScan | @Statistcs | @SwapTables | \
                            @SystemCatalog | @SystemInformation | @UpdateApplicationCatalog | \
                            @UpdateClasses | @UpdateLogging

# Note: the following System Stored Procedures are deliberately omitted above
# (& below), because we do not want to stop, pause, or resume the VoltDB server,
# nor modify the cluster, etc.: @Pause, @Promote, @Quiesce, @Resume, @Shutdown,
# @StopNode; also, you cannot explicitly (using 'exec') call @AdHoc within sqlcmd
# (but it is called implicitly, every time you type a normal SQL statement).

# TODO: may want to include the use of @AdHocLarge
#                            @AdHocLarge '{sql-statement}' | \
system-stored-proc      ::= @Explain '{sql-statement}' | @ExplainProc '{stored-proc-name}' | @ExplainView '{view-name}' | \
                            @GetPartitionKeys {partition-keys-datatype} | \
                            @Statistics {statistics-component}[,] {digit-0-or-1} | \
                            @SwapTables {swappable-tables} | \
                            @SystemCatalog {system-catalog-component}  | \
                            @SystemInformation {system-info-component} | \
                            @UpdateApplicationCatalog NULL[,] {config-file-name} | \
                            @UpdateClasses {jar-file-name} {java-class-selector} | \
                            @UpdateLogging {log4j-file-name}

partition-keys-datatype ::= INTEGER 2| VARBINARY 2| STRING | VARCHAR | \
                            integer 2| varbinary 2| string | varchar | \
                            '{partition-keys-datatype}'
statistics-component    ::= COMMANDLOG | CPU | DRCONSUMER | DRPRODUCER | DRROLE | IMPORTER | INDEX | INITIATOR | \
                            IOSTATS | LATENCY | LIVECLIENTS | MANAGEMENT | MEMORY | PARTITIONCOUNT | PLANNER | \
                            PROCEDURE | PROCEDUREDETAIL | PROCEDUREINPUT | PROCEDUREOUTPUT | PROCEDUREPROFILE | \
                            QUEUE | REBALANCE | SNAPSHOTSTATUS | TABLE | \
                            '{statistics-component}' 5| \
                            commandlog | cpu | drconsumer | drproducer | drrole | importer | index | initiator | \
                            iostats | latency | liveclient | management | memory | partitioncount | planner | \
                            procedure | proceduredetail | procedureinput | procedureoutput | procedureprofile | \
                            queue | rebalance | snapshotstatus | table
system-catalog-component::= COLUMNS | FUNCTIONS | INDEXINFO | PRIMARYKEYS | PROCEDURECOLUMNS | PROCEDURES | TABLES | \
                            columns | functions | indexinfo | primarykeys | procedurecolumns | procedures | tables | \
                            '{system-catalog-component}'
system-info-component   ::= DEPLOYMENT 2| OVERVIEW 2| deployment 2| overview 2| \
                            '{system-info-component}'

# Some arbitrary (deployment, log4j & jar) config files that are normally found
# within the VoltDB (community) GitHub directories, to be used with some of the
# System Stored Procedures above. Note that the paths are relative to the <voltdb>
# directory, so these will work best when SQL-grammar-gen is run from there; but
# there is also a small chance of prepending '../../' to the paths, in which case
# they will work from the <voltdb>/tests/sqlgrammar/ directory (or some other
# directory two levels down from <voltdb>). However, they will not work at all
# when running from directories other than those.
config-file-name        ::= {config-file-path}  9|  ../../{config-file-path} | \
                           '{config-file-path}' 9| '../../{config-file-path}'
config-file-path        ::= doc/tutorials/auction/deployment.xml | \
                            doc/tutorials/helloworld/deployment.xml | \
                            doc/tutorials/helloworldrevisited/deployment.xml | \
                            tests/geb/vmc/server/deployment.xml | \
                            tests/geb/vmc/server/deploy_pro.xml | \
                            tests/test_apps/log4jsocketimporter/deployment.xml
# TODO: temporarily removed this because it causes a crash (ENG-13394):
#                            tests/test_apps/socketimporter/deployment-log4j.xml
log4j-file-name         ::= {log4j-file-path}  9|  ../../{log4j-file-path} | \
                           '{log4j-file-path}' 9| '../../{log4j-file-path}'
log4j-file-path         ::= voltdb/log4j.xml | \
                            tests/log4j-allconsole.xml | \
                            tests/test_apps/live-rejoin-consistency/log4j.xml | \
                            tests/test_apps/log4jsocketimporter/log4j.xml
jar-file-name           ::= {jar-file-path}  9|  ../../{jar-file-path} | \
                           '{jar-file-path}' 9| '../../{jar-file-path}'
jar-file-path           ::= NULL 16| testgrammar.jar 4| \
                            testfuncs.jar 3| testfuncs_alternative.jar | \
                            doc/tutorials/auction/auction-client.jar | \
                            doc/tutorials/auction/auction-procs.jar | \
                            doc/tutorials/helloworld/helloworld.jar | \
                            doc/tutorials/helloworldrevisited/helloworld.jar | \
                            examples/geospatial/geospatial-client.jar | \
                            examples/geospatial/geospatial-procs.jar | \
                            examples/voter/voter-client.jar | \
                            examples/voter/voter-procs.jar
java-class-selector     ::= "" 16| "sqlgrammartest.*" 2| "sqlgrammartest.{java-proc-name}" 2| \
                            "org.voltdb_testfuncs.*" 2| "org.voltdb_testfuncs.UserDefinedTestFunctions" 2| \
                            "com.auctionexample[[.debug]][[.datafiles]].*" 2| \
                            "geospatial.*" 2| "voter.*" 2| \
                            "Client" | "SignIn"

################################################################################
# Default Stored Procedures
#
default-proc-name       ::= {table-name}.{default-proc-suffix}
default-proc-suffix     ::= delete | insert | select | update | upsert

# The number and type of parameters used by a Default Stored Procedure (e.g.
# R1.delete or P2.insert) depends on both the "suffix name" of the procedure
# (delete, insert, select, update, or upsert) and on the number and type of the
# table's primary key column(s); note that only certain column types are allowed
# in a primary key.
default-stored-proc     ::= {table-name-w-pk-int}.delete {integer-value} | \
                            {table-name-w-pk-int}.select {integer-value} | \
                            {table-name-w-pk-int}.insert {insert-values-all-val} | \
                            {table-name-w-pk-int}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-int}.update {insert-values-all-val} {integer-value} | \
                            {table-name-w-pk-str}.delete {string-value}  | \
                            {table-name-w-pk-str}.select {string-value}  | \
                            {table-name-w-pk-str}.insert {insert-values-all-val} | \
                            {table-name-w-pk-str}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-str}.update {insert-values-all-val} {string-value} | \
                            {table-name-w-pk-varbin}.delete {varbinary-value}  | \
                            {table-name-w-pk-varbin}.select {varbinary-value}  | \
                            {table-name-w-pk-varbin}.insert {insert-values-all-val} | \
                            {table-name-w-pk-varbin}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-varbin}.update {insert-values-all-val} {varbinary-value} | \
                            {table-name-w-pk-int-str}.delete {integer-value} {string-value} | \
                            {table-name-w-pk-int-str}.select {integer-value} {string-value} | \
                            {table-name-w-pk-int-str}.insert {insert-values-all-val} | \
                            {table-name-w-pk-int-str}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-int-str}.update {insert-values-all-val} {integer-value} {string-value} | \
                            {table-name-w-pk-str-int}.delete {string-value} {integer-value} | \
                            {table-name-w-pk-str-int}.select {string-value} {integer-value} | \
                            {table-name-w-pk-str-int}.insert {insert-values-all-val} | \
                            {table-name-w-pk-str-int}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-str-int}.update {insert-values-all-val} {string-value} {integer-value} | \
                            {table-name-w-pk-i-s-v}.delete {integer-value} {string-value} {varbinary-value} | \
                            {table-name-w-pk-i-s-v}.select {integer-value} {string-value} {varbinary-value} | \
                            {table-name-w-pk-i-s-v}.insert {insert-values-all-val} | \
                            {table-name-w-pk-i-s-v}.upsert {insert-values-all-val} | \
                            {table-name-w-pk-i-s-v}.update {insert-values-all-val} {integer-value} {string-value} {varbinary-value}

################################################################################
# User-defined Stored Procedures
#
user-stored-proc        ::= {user-proc-0params} 2| {user-proc-1param} {integer-value}

################################################################################
# Grammar rules for a SELECT statement (lots of these!):
################################################################################
#
select-statement        ::= {basic-select-statement}  8| \
                            {groupby-select-statement} | \
                            {select-statement} {set-operator} {select-statement}
set-operator            ::= UNION [ALL] | INTERSECT [ALL] | EXCEPT

# Putting the "top-clause" and "all-or-distinct" in more than one set of
# brackets makes them less likely
basic-select-statement  ::= SELECT {top-all-or-distinct} {select-list} {from-clause}
top-all-or-distinct     ::= [[[{top-clause}]]] [[{all-or-distinct}]]
from-clause             ::= {simple-from-clause} [[[[{group-clause}]]]] [{sort-clause}] 38| \
                            {from-clause-with-t0} | {from-clause-with-t1}
simple-from-clause      ::= FROM {table-refs} [[{where-clause}]]
from-clause-no-limit    ::= FROM {table-refs} [[{where-clause}]] {group-order-no-limit} 38| \
                            {from-clause-with-t0} | {from-clause-with-t1}
group-order-no-limit    ::= [[[[{group-clause}]]]] [{order-by-clause}]

all-or-distinct         ::= ALL | DISTINCT
select-list             ::= {select-list-item}[[, {select-list}]]
select-list-item        ::= {star} 5| {column-table-ref} [[AS ]{column-alias-set}] 14| \
                            {window-function-expr} [[AS ]{column-alias-set}]

column-name-or-alias    ::= {any-column-name} 9| {column-alias-ref}
column-expression       ::= {column-table-ref} 3| {selection-expression}
column-reference        ::= {column-table-ref} 18| {column-alias-ref} | \
                            {selection-expression}

# Putting the ", {table-ref-list}" in more than one set of brackets makes it less likely
table-refs              ::= {table-list} 16| {table-ref-list} 3| {join-clause}
table-ref-list          ::= {table-ref-set}[[[[, {table-ref-list}]]]]
table-list              ::= {table-reference-t1} \
                            [[[[, {table-reference-t2} \
                              [[, {table-reference-t3} \
                              [[, {table-reference-t4} \
                              [[, {table-reference-t5}]] ]] ]] ]]]]

# Table/view/sub-query references that can be reused later in a SQL statement,
# as ":t1", ":t2", etc.
table-name-or-alias-t1  ::= {table-name:t1} 2| {table-name}[ AS] {table-alias:t1}
table-reference-t1      ::= {table-name-or-alias-t1} 6| \
                            {view-name:t1}  2| {view-name}[  AS] {table-alias:t1} | \
                            {sub-query}[ AS] {table-alias:t1}

table-reference-t2      ::= {table-name:t2} 4| {table-name}[ AS] {table-alias:t2} 2| \
                            {view-name:t2}  2| {view-name}[  AS] {table-alias:t2}  | \
                            {sub-query}[ AS] {table-alias:t2}

table-reference-t3      ::= {table-name:t3} 4| {table-name}[ AS] {table-alias:t3} 2| \
                            {view-name:t3}  2| {view-name}[  AS] {table-alias:t3}  | \
                            {sub-query}[ AS] {table-alias:t3}

table-reference-t4      ::= {table-name:t4} 4| {table-name}[ AS] {table-alias:t4} 2| \
                            {view-name:t4}  2| {view-name}[  AS] {table-alias:t4}  | \
                            {sub-query}[ AS] {table-alias:t4}

table-reference-t5      ::= {table-name:t5} 4| {table-name}[ AS] {table-alias:t5} 2| \
                            {view-name:t5}  2| {view-name}[  AS] {table-alias:t5}  | \
                            {sub-query}[ AS] {table-alias:t5}

# Defining these separately so that they can optionally be overridden, for use
# with SQLCoverage, to avoid syntax (TOP) not supported by PostgreSQL, and
# issues with Geospatial types (point & polygon), where using * can be a problem
star                    ::= *
top-clause              ::= TOP {non-negative-int-value}
top-one                 ::= TOP 1   98| TOP 0   | TOP {byte-non-null-value}
limit-one               ::= LIMIT 1 98| LIMIT 0 | LIMIT {byte-non-null-value}

# PostgreSQL-compatible versions of the above: avoids problems involving SELECT *
# with Geospatial types; and involving TOP, which PostgreSQL does not support.
# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
pg-star                 ::= ID, TINY, SMALL, INT1, BIG, NUM, DEC, \
                            VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR_OUTLINE_MIN, VCHAR, VCHAR_JSON, \
                            TIME1, VARBIN, AsText(POINT), AsText(POLYGON), \
                            IPV4, IPV6, VBIPV4, VBIPV6
pg-top-clause           ::=
pg-top-one              ::=

where-clause            ::= WHERE {boolean-expression}
boolean-expression      ::=  [NOT   ]{boolean-type-expr}   [[{and-or} {boolean-expression}]] 8| \
                            [[NOT ]]({boolean-expression}) [[{and-or} {boolean-expression}]] 2| \
                            {correlated-bool-expr}
and-or                  ::= AND | OR

group-clause            ::= GROUP BY {group-by-list} [HAVING {boolean-expression}]
order-by-clause         ::= ORDER BY {order-by-list}
sort-clause             ::= [{order-by-clause}] [LIMIT {non-negative-int-value}] [OFFSET {non-negative-int-value}]
group-by-list           ::= {column-reference}[,[[            ]] {group-by-list}]
order-by-list           ::= {column-reference}[ {asc-or-desc}][, {order-by-list}]
asc-or-desc             ::= ASC | DESC

# PostgreSQL-compatible version of the above: avoids LIMIT or OFFSET without
# ORDER BY; and sorts by ID, which is typically the primary key
pg-sort-clause          ::= {order-by-clause}, ID [LIMIT {non-negative-int-value}] [OFFSET {non-negative-int-value}]

value-expression        ::= {numeric-expression}  7| {string-expression}     4| {timestamp-expression} | \
                            {json-expression}      | {string-ipv4-expression} | {string-ipv6-expression} | \
                            {varbinary-expression} | {varbin-ipv4-expression} | {varbin-ipv6-expression} | \
                            {point-expression}     | {polygon-expression}
selection-expression    ::= {value-expression} 18| COUNT(DISTINCT {value-expression}) | COUNT(*)
boolean-type-expr       ::= {column-expression} IS [NOT ]NULL | {sub-query} IS [NOT ]NULL | \
                            {boolean-numeric-expr}  7| {boolean-string-expr} 4| {boolean-timestamp-expr} | \
                            {boolean-varbinary-expr} | {boolean-point-expr}   | {boolean-polygon-expr} | \
                            EXISTS {sub-query}
boolean-numeric-expr    ::= {numeric-expression}   {comparison-operator} {numeric-expression}   4| \
                            {numeric-column-name}   IN {numeric-sub-query}
boolean-string-expr     ::= {string-expression}    {comparison-operator} {string-expression}    4| \
                            {string-column-name}    IN {string-sub-query} | \
                            {string-like-expression}
boolean-timestamp-expr  ::= {timestamp-expression} {comparison-operator} {timestamp-expression} 4| \
                            {timestamp-column-name} IN {timestamp-sub-query} | \
                            {bool-val-timestamp-expr}
boolean-varbinary-expr  ::= {varbinary-expression} {comparison-operator} {varbinary-expression} 4| \
                            {varbinary-column-name} IN {varbinary-sub-query}
boolean-point-expr      ::= {point-expression} {comparison-operator} {point-expression} 4| \
                            {point-column-name}     IN {point-sub-query}
boolean-polygon-expr    ::= {polygon-expression} {comparison-operator} {polygon-expression} 4| \
                            {polygon-column-name}   IN {polygon-sub-query} | \
                            {bool-valued-polygon-expr}
comparison-operator     ::= {simple-comparison-op} 19| {str-comparison-operator}
simple-comparison-op    ::= = 3| <> | != | < | > | <= | >= | IS NOT DISTINCT FROM
str-comparison-operator ::= {simple-comparison-op} | LIKE | STARTS WITH

################################################################################
# GROUP BY clauses, and the SELECT statements that use them; including SELECT
# statements without GROUP BY that use aggregate functions in a similar way
#
groupby-select-statement::= {simple-groupby-select} 3| {random-groupby-select}

simple-groupby-select   ::= SELECT [{top-all-or-distinct}] {groupby-select-list} \
                            {simple-from-clause:sfc} {groupby-w-column-list}

groupby-select-list     ::= {groupby-column-list;gcl}{comma;cm1}{comma;cm2} \
                            {count-star}{comma;cm3} {aggregate-func-terms}
comma                   ::= ,
count-star              ::= COUNT(*) {count-star-alias:csa}{empty:cm2} 3| \
                            {empty:cm1}{empty:csa}{empty:cm3}
count-star-alias        ::= CS

groupby-w-column-list   ::= GROUP BY {groupby-column-list0} 4| \
                            {empty:gcl}{empty:cm1}{empty:cm2}
groupby-column-list0    ::= {groupby-column-list:gcl}
groupby-column-list     ::= {groupby-col-name-set}[, {groupby-column-list}]

groupby-col-name-set    ::= {any-column-name:gc0,gc1,gc2,gc3,gc4,gc5,gc6,gc7,gc8,gc9,gc10,gc11,gc12,gc13,gc14,gc15,gc16,gc17,gc18,gc19:1}

aggregate-func-terms    ::= {aggregate-func-terms0} 4| {empty:cm2}{empty:cm3}
aggregate-func-terms0   ::= {aggregate-func-term}[, {aggregate-func-terms0}]
aggregate-func-term     ::=   {aggr-func-for-group-by}({num-aggr-col-name-set})  9| \
                            {non-num-arg-aggr-func-gb}({aggregate-col-name-set}) 9| \
                                        COUNT(DISTINCT {aggregate-col-name-set})

aggregate-col-name-set  ::= {any-column-name:ac0,ac1,ac2,ac3,ac4,ac5,ac6,ac7,ac8,ac9,ac10,ac11,ac12,ac13,ac14,ac15,ac16,ac17,ac18,ac19}
num-aggr-col-name-set   ::= {numeric-column-name:ac0,ac1,ac2,ac3,ac4,ac5,ac6,ac7,ac8,ac9,ac10,ac11,ac12,ac13,ac14,ac15,ac16,ac17,ac18,ac19}
aggregate-col-name-list ::= {;ac0,ac1,ac2,ac3,ac4,ac5,ac6,ac7,ac8,ac9,ac10,ac11,ac12,ac13,ac14,ac15,ac16,ac17,ac18,ac19;', '}

# A CREATE VIEW statement needs to include a 'simple' SELECT statement,
# usually using a GROUP BY clause (i.e., a {simple-groupby-select}); this
# 'create-view-column-list' makes sure that the number, names, and types
# of the columns match (mostly)
create-view-column-list ::= {groupby-column-list;gcl}{comma;cm1}{comma;cm2} \
                            {count-star-alias;csa}{comma;cm3} {aggregate-col-name-list}

# TODO: better support for SELECT ... GROUP BY statements, without the
# restrictions that exist for CREATE VIEW, e.g., no HAVING or ORDER BY
# clauses; for now, only the CREATE VIEW types are supported
random-groupby-select   ::= {simple-groupby-select}

################################################################################
# Joins, of various types, including multi-joins of up to 5 tables
#
join-clause             ::= {table-reference-t1} [{join-type} ]JOIN {table-reference-t2} {join-condition1} \
                                              [[ [{join-type} ]JOIN {table-reference-t3} {join-condition2} \
                                               [ [{join-type} ]JOIN {table-reference-t4} {join-condition3} \
                                               [ [{join-type} ]JOIN {table-reference-t5} {join-condition4} ]] ]]
join-type               ::= INNER | {left-or-right}[ OUTER]
left-or-right           ::= LEFT | RIGHT | FULL

join-condition1         ::= USING ({column-name-or-alias:cj1}) 2| \
                            ON {:t1}.{column-name-or-alias:cj1} = {:t2}.{:cj1} | \
                            ON {:t2}.{column-name-or-alias:cj1} = {:t1}.{:cj1} | \
                            ON {:t1}.{column-name-or-alias} {comparison-operator} {:t2}.{column-name-or-alias} | \
                            ON {:t2}.{column-name-or-alias} {comparison-operator} {:t1}.{column-name-or-alias}
join-condition2         ::= USING ({column-name-or-alias:cj2}) 2| \
                            ON {:t2}.{column-name-or-alias:cj2} = {:t3}.{:cj2} | \
                            ON {:t3}.{column-name-or-alias:cj2} = {:t1}.{:cj2} | \
                            ON {:t3}.{column-name-or-alias} {comparison-operator} {:t1}.{column-name-or-alias} | \
                            ON {:t2}.{column-name-or-alias} {comparison-operator} {:t3}.{column-name-or-alias}
join-condition3         ::= USING ({column-name-or-alias:cj3}) 2| \
                            ON {:t3}.{column-name-or-alias:cj3} = {:t4}.{:cj3} | \
                            ON {:t4}.{column-name-or-alias:cj3} = {:t1}.{:cj3} | \
                            ON {:t2}.{column-name-or-alias} {comparison-operator} {:t4}.{column-name-or-alias} | \
                            ON {:t4}.{column-name-or-alias} {comparison-operator} {:t3}.{column-name-or-alias}
join-condition4         ::= USING ({column-name-or-alias:cj4}) 2| \
                            ON {:t1}.{column-name-or-alias:cj4} = {:t5}.{:cj4} | \
                            ON {:t5}.{column-name-or-alias:cj4} = {:t4}.{:cj4} | \
                            ON {:t2}.{column-name-or-alias} {comparison-operator} {:t5}.{column-name-or-alias} | \
                            ON {:t5}.{column-name-or-alias} {comparison-operator} {:t3}.{column-name-or-alias}

################################################################################
# Sub-queries, scalar and otherwise, of various types
#
sub-query               ::= ({select-statement}) 3| {scalar-sub-query}
scalar-sub-query        ::= {numeric-scalar-sub-q}  7| {string-scalar-sub-q}   4| \
                            {timestamp-scalar-sub-q} | {varbinary-scalar-sub-q} | \
                            {point-scalar-sub-q}     | {polygon-scalar-sub-q}

numeric-sub-query       ::= (SELECT {top-all-or-distinct}   {numeric-expression} {from-clause})
string-sub-query        ::= (SELECT {top-all-or-distinct}    {string-expression} {from-clause})
timestamp-sub-query     ::= (SELECT {top-all-or-distinct} {timestamp-expression} {from-clause})
varbinary-sub-query     ::= (SELECT {top-all-or-distinct} {varbinary-expression} {from-clause})
point-sub-query         ::= (SELECT {top-all-or-distinct}     {point-expression} {from-clause})
polygon-sub-query       ::= (SELECT {top-all-or-distinct}   {polygon-expression} {from-clause})
numeric-scalar-sub-q    ::= (SELECT  {aggregate-function}({numeric-expression})  {from-clause}) 3| \
                            (SELECT {num-result-aggr-func}({column-expression})  {from-clause}) 3| \
                            (SELECT         COUNT(DISTINCT {column-expression})  {from-clause})  | \
                            (SELECT         COUNT(*)                             {from-clause})  | \
                            (SELECT {top-one}   {numeric-expression} {from-clause-no-limit})     | \
                            (SELECT             {numeric-expression} {from-clause-no-limit} {limit-one})
integer-scalar-sub-q    ::= (SELECT  {aggregate-function}({int-expression})      {from-clause}) 3| \
                            (SELECT {num-result-aggr-func}({column-expression})  {from-clause}) 3| \
                            (SELECT         COUNT(DISTINCT {column-expression})  {from-clause})  | \
                            (SELECT         COUNT(*)                             {from-clause})  | \
                            (SELECT {top-one}   {int-expression}     {from-clause-no-limit})     | \
                            (SELECT             {int-expression}     {from-clause-no-limit} {limit-one})
string-scalar-sub-q     ::= (SELECT {non-num-aggregate-func}({string-expression})  {from-clause}) 6| \
                            (SELECT {top-one}    {string-expression} {from-clause-no-limit})       | \
                            (SELECT              {string-expression} {from-clause-no-limit} {limit-one})
json-scalar-sub-q       ::= (SELECT {non-num-aggregate-func}({json-expression})  {from-clause}) 6| \
                            (SELECT {top-one}    {json-expression} {from-clause-no-limit})       | \
                            (SELECT              {json-expression} {from-clause-no-limit} {limit-one})
timestamp-scalar-sub-q  ::= (SELECT {non-num-aggregate-func}({timestamp-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {timestamp-expression} {from-clause-no-limit})         | \
                            (SELECT           {timestamp-expression} {from-clause-no-limit} {limit-one})
varbinary-scalar-sub-q  ::= (SELECT {non-num-aggregate-func}({varbinary-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {varbinary-expression} {from-clause-no-limit})         | \
                            (SELECT           {varbinary-expression} {from-clause-no-limit} {limit-one})
point-scalar-sub-q      ::= (SELECT {non-num-aggregate-func}({point-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {point-expression} {from-clause-no-limit})         | \
                            (SELECT           {point-expression} {from-clause-no-limit} {limit-one})
polygon-scalar-sub-q    ::= (SELECT {non-num-aggregate-func}({polygon-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {polygon-expression} {from-clause-no-limit})         | \
                            (SELECT           {polygon-expression} {from-clause-no-limit} {limit-one})
str-ipv4-scalar-sub-q   ::= (SELECT {non-num-aggregate-func}({string-ipv4-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {string-ipv4-expression} {from-clause-no-limit})         | \
                            (SELECT           {string-ipv4-expression} {from-clause-no-limit} {limit-one})
str-ipv6-scalar-sub-q   ::= (SELECT {non-num-aggregate-func}({string-ipv6-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {string-ipv6-expression} {from-clause-no-limit})         | \
                            (SELECT           {string-ipv6-expression} {from-clause-no-limit} {limit-one})
varb-ipv4-scalar-sub-q  ::= (SELECT {non-num-aggregate-func}({varbin-ipv4-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {varbin-ipv4-expression} {from-clause-no-limit})         | \
                            (SELECT           {varbin-ipv4-expression} {from-clause-no-limit} {limit-one})
varb-ipv6-scalar-sub-q  ::= (SELECT {non-num-aggregate-func}({varbin-ipv6-expression}) {from-clause}) 6| \
                            (SELECT {top-one} {varbin-ipv6-expression} {from-clause-no-limit})         | \
                            (SELECT           {varbin-ipv6-expression} {from-clause-no-limit} {limit-one})

################################################################################
# Used to create correlated expressions and sub-queries, referring to a "T0"
# table (or view) alias; that is, a boolean expression or sub-query that
# compares the values from its own table (or view) with those of "T0" which
# was defined in the outer query
#

correlated-t0-bool-expr ::= {corltd-t0-bool-simp-expr}  | {corltd-t0-bool-subq-expr}
correlated-t0-bool-expr2::= {corltd-t0-bool-simp-expr} 9| {corltd-t0-bool-subq-expr}
corltd-t0-bool-simp-expr::= {numeric-expression}   {comparison-operator} {t0}.{numeric-column-name}  7| \
                            {string-expression}    {comparison-operator} {t0}.{string-column-name}   4| \
                            {timestamp-expression} {comparison-operator} {t0}.{timestamp-column-name} | \
                            {varbinary-expression} {comparison-operator} {t0}.{varbinary-column-name} | \
                            {point-expression}     {comparison-operator} {t0}.{point-column-name}     | \
                            {polygon-expression}   {comparison-operator} {t0}.{polygon-column-name}   | \
                            {t0}.{numeric-column-name}   {comparison-operator} {numeric-expression}  7| \
                            {t0}.{string-column-name}    {comparison-operator} {string-expression}   4| \
                            {t0}.{timestamp-column-name} {comparison-operator} {timestamp-expression} | \
                            {t0}.{varbinary-column-name} {comparison-operator} {varbinary-expression} | \
                            {t0}.{point-column-name}     {comparison-operator} {point-expression}     | \
                            {t0}.{polygon-column-name}   {comparison-operator} {polygon-expression}
corltd-t0-bool-subq-expr::= {numeric-expression}   {comparison-operator} ({numeric-corltd-t0-subq})   7| \
                            {string-expression}    {comparison-operator} ({string-corltd-t0-subq})    4| \
                            {timestamp-expression} {comparison-operator} ({timestamp-corltd-t0-subq})  | \
                            {varbinary-expression} {comparison-operator} ({varbinary-corltd-t0-subq})  | \
                            {point-expression}     {comparison-operator} ({point-corltd-t0-subq})      | \
                            {polygon-expression}   {comparison-operator} ({polygon-corltd-t0-subq})    | \
                            ({numeric-corltd-t0-subq})   {comparison-operator} {numeric-expression}   7| \
                            ({string-corltd-t0-subq})    {comparison-operator} {string-expression}    4| \
                            ({timestamp-corltd-t0-subq}) {comparison-operator} {timestamp-expression}  | \
                            ({varbinary-corltd-t0-subq}) {comparison-operator} {varbinary-expression}  | \
                            ({point-corltd-t0-subq})     {comparison-operator} {point-expression}      | \
                            ({polygon-corltd-t0-subq})   {comparison-operator} {polygon-expression}

numeric-corltd-t0-subq  ::= SELECT  {aggregate-function}({numeric-expression}) {from-clause-corltd-t0} 3| \
                            SELECT {num-result-aggr-func}({column-expression}) {from-clause-corltd-t0} 3| \
                            SELECT         COUNT(DISTINCT {column-expression}) {from-clause-corltd-t0}  | \
                            SELECT         COUNT(*)                            {from-clause-corltd-t0}  | \
                            SELECT {top-one}             {numeric-expression}  {from-clause-corltd-t0}  | \
                            SELECT                       {numeric-expression}  {from-clause-corltd-t0} {limit-one}
string-corltd-t0-subq   ::= SELECT {non-num-aggregate-func}({string-expression}) {from-clause-corltd-t0} 6| \
                            SELECT {top-one}                {string-expression}  {from-clause-corltd-t0}  | \
                            SELECT                          {string-expression}  {from-clause-corltd-t0} {limit-one}
timestamp-corltd-t0-subq::= SELECT {non-num-aggregate-func}({timestamp-expression}) {from-clause-corltd-t0} 6| \
                            SELECT {top-one}                {timestamp-expression}  {from-clause-corltd-t0}  | \
                            SELECT                          {timestamp-expression}  {from-clause-corltd-t0} {limit-one}
varbinary-corltd-t0-subq::= SELECT {non-num-aggregate-func}({varbinary-expression}) {from-clause-corltd-t0} 6| \
                            SELECT {top-one}                {varbinary-expression}  {from-clause-corltd-t0}  | \
                            SELECT                          {varbinary-expression}  {from-clause-corltd-t0} {limit-one}
point-corltd-t0-subq    ::= SELECT {non-num-aggregate-func}({point-expression}) {from-clause-corltd-t0} 6| \
                            SELECT {top-one}                {point-expression}  {from-clause-corltd-t0}  | \
                            SELECT                          {point-expression}  {from-clause-corltd-t0} {limit-one}
polygon-corltd-t0-subq  ::= SELECT {non-num-aggregate-func}({polygon-expression}) {from-clause-corltd-t0} 6| \
                            SELECT {top-one}                {polygon-expression}  {from-clause-corltd-t0}  | \
                            SELECT                          {polygon-expression}  {from-clause-corltd-t0} {limit-one}
from-clause-corltd-t0   ::= FROM {table-or-view-name}      WHERE {correlated-t0-bool-expr2} [{group-order-no-limit}]
from-clause-with-t0     ::= FROM {table-or-view-name} {t0} WHERE {corltd-t0-bool-subq-expr} [{group-order-no-limit}]

# Same idea as above, but without using a "T0" alias; instead, the same actual
# table name (referred to here as {:t1}) is used again
correlated-t1-bool-expr ::= {corltd-t1-bool-simp-expr}  | {corltd-t1-bool-subq-expr}
correlated-t1-bool-expr2::= {corltd-t1-bool-simp-expr} 9| {corltd-t1-bool-subq-expr}
corltd-t1-bool-simp-expr::= {numeric-expression}   {comparison-operator} {:t1}.{numeric-column-name}  7| \
                            {string-expression}    {comparison-operator} {:t1}.{string-column-name}   4| \
                            {timestamp-expression} {comparison-operator} {:t1}.{timestamp-column-name} | \
                            {varbinary-expression} {comparison-operator} {:t1}.{varbinary-column-name} | \
                            {point-expression}     {comparison-operator} {:t1}.{point-column-name}     | \
                            {polygon-expression}   {comparison-operator} {:t1}.{polygon-column-name}   | \
                            {:t1}.{numeric-column-name}   {comparison-operator} {numeric-expression}  7| \
                            {:t1}.{string-column-name}    {comparison-operator} {string-expression}   4| \
                            {:t1}.{timestamp-column-name} {comparison-operator} {timestamp-expression} | \
                            {:t1}.{varbinary-column-name} {comparison-operator} {varbinary-expression} | \
                            {:t1}.{point-column-name}     {comparison-operator} {point-expression}     | \
                            {:t1}.{polygon-column-name}   {comparison-operator} {polygon-expression}
corltd-t1-bool-subq-expr::= {numeric-expression}   {comparison-operator} ({numeric-corltd-t1-subq})    7| \
                            {string-expression}    {comparison-operator} ({string-corltd-t1-subq})     4| \
                            {timestamp-expression} {comparison-operator} ({timestamp-corltd-t1-subq})   | \
                            {varbinary-expression} {comparison-operator} ({varbinary-corltd-t1-subq})   | \
                            {point-expression}     {comparison-operator} ({point-corltd-t1-subq})       | \
                            {polygon-expression}   {comparison-operator} ({polygon-corltd-t1-subq})     | \
                            ({numeric-corltd-t1-subq})   {comparison-operator} {numeric-expression}    7| \
                            ({string-corltd-t1-subq})    {comparison-operator} {string-expression}     4| \
                            ({timestamp-corltd-t1-subq}) {comparison-operator} {timestamp-expression}   | \
                            ({varbinary-corltd-t1-subq}) {comparison-operator} {varbinary-expression}   | \
                            ({point-corltd-t1-subq})     {comparison-operator} {point-expression}       | \
                            ({polygon-corltd-t1-subq})   {comparison-operator} {polygon-expression}

numeric-corltd-t1-subq  ::= SELECT  {aggregate-function}({numeric-expression}) {from-clause-corltd-t1} 3| \
                            SELECT {num-result-aggr-func}({column-expression}) {from-clause-corltd-t1} 3| \
                            SELECT         COUNT(DISTINCT {column-expression}) {from-clause-corltd-t1}  | \
                            SELECT         COUNT(*)                            {from-clause-corltd-t1}  | \
                            SELECT {top-one}             {numeric-expression}  {from-clause-corltd-t1}  | \
                            SELECT                       {numeric-expression}  {from-clause-corltd-t1} {limit-one}
string-corltd-t1-subq   ::= SELECT {non-num-aggregate-func}({string-expression}) {from-clause-corltd-t1} 6| \
                            SELECT {top-one}                {string-expression}  {from-clause-corltd-t1}  | \
                            SELECT                          {string-expression}  {from-clause-corltd-t1} {limit-one}
timestamp-corltd-t1-subq::= SELECT {non-num-aggregate-func}({timestamp-expression}) {from-clause-corltd-t1} 6| \
                            SELECT {top-one}                {timestamp-expression}  {from-clause-corltd-t1}  | \
                            SELECT                          {timestamp-expression}  {from-clause-corltd-t1} {limit-one}
varbinary-corltd-t1-subq::= SELECT {non-num-aggregate-func}({varbinary-expression}) {from-clause-corltd-t1} 6| \
                            SELECT {top-one}                {varbinary-expression}  {from-clause-corltd-t1}  | \
                            SELECT                          {varbinary-expression}  {from-clause-corltd-t1} {limit-one}
point-corltd-t1-subq    ::= SELECT {non-num-aggregate-func}({point-expression}) {from-clause-corltd-t1} 6| \
                            SELECT {top-one}                {point-expression}  {from-clause-corltd-t1}  | \
                            SELECT                          {point-expression}  {from-clause-corltd-t1} {limit-one}
polygon-corltd-t1-subq  ::= SELECT {non-num-aggregate-func}({polygon-expression}) {from-clause-corltd-t1} 6| \
                            SELECT {top-one}                {polygon-expression}  {from-clause-corltd-t1}  | \
                            SELECT                          {polygon-expression}  {from-clause-corltd-t1} {limit-one}
from-clause-corltd-t1   ::= FROM {table-or-view-name}    WHERE {correlated-t1-bool-expr2} [{group-order-no-limit}]
from-clause-with-t1     ::= FROM {table-or-view-name:t1} WHERE {corltd-t1-bool-subq-expr} [{group-order-no-limit}]

# Similar ideas to the above, but returning values of a certain specified type,
# rather than a boolean value
corltd-t0-numeric-expr  ::= ({numeric-corltd-t0-subq})   3| {t0}.{numeric-column-name}
corltd-t0-string-expr   ::= ({string-corltd-t0-subq})    3| {t0}.{string-column-name}
corltd-t0-timestamp-expr::= ({timestamp-corltd-t0-subq}) 3| {t0}.{timestamp-column-name}
corltd-t0-varbinary-expr::= ({varbinary-corltd-t0-subq}) 3| {t0}.{varbinary-column-name}
corltd-t0-point-expr    ::= ({point-corltd-t0-subq})     3| {t0}.{point-column-name}
corltd-t0-polygon-expr  ::= ({polygon-corltd-t0-subq})   3| {t0}.{polygon-column-name}

corltd-t1-numeric-expr  ::= ({numeric-corltd-t1-subq})   3| {:t1}.{numeric-column-name}
corltd-t1-string-expr   ::= ({string-corltd-t1-subq})    3| {:t1}.{string-column-name}
corltd-t1-timestamp-expr::= ({timestamp-corltd-t1-subq}) 3| {:t1}.{timestamp-column-name}
corltd-t1-varbinary-expr::= ({varbinary-corltd-t1-subq}) 3| {:t1}.{varbinary-column-name}
corltd-t1-point-expr    ::= ({point-corltd-t1-subq})     3| {:t1}.{point-column-name}
corltd-t1-polygon-expr  ::= ({polygon-corltd-t1-subq})   3| {:t1}.{polygon-column-name}

# Similar idea to the above, but in a generic SELECT statement, where a table
# alias of T0 or {table-name:t1} may or may not have been used
correlated-bool-expr    ::= {numeric-expression}   {comparison-operator} {table-ref}.{numeric-column-name}  7| \
                            {string-expression}    {comparison-operator} {table-ref}.{string-column-name}   4| \
                            {timestamp-expression} {comparison-operator} {table-ref}.{timestamp-column-name} | \
                            {table-ref}.{numeric-column-name}   {comparison-operator} {numeric-expression}  7| \
                            {table-ref}.{string-column-name}    {comparison-operator} {string-expression}   4| \
                            {table-ref}.{timestamp-column-name} {comparison-operator} {timestamp-expression} | \
                            {numeric-expression}   {comparison-operator} {table-name:t1}.{numeric-column-name} 14| \
                            {string-expression}    {comparison-operator} {table-name:t1}.{string-column-name}   8| \
                            {timestamp-expression} {comparison-operator} {table-name:t1}.{timestamp-column-name} | \
                            {table-name:t1}.{numeric-column-name}   {comparison-operator} {numeric-expression} 14| \
                            {table-name:t1}.{string-column-name}    {comparison-operator} {string-expression}   8| \
                            {table-name:t1}.{timestamp-column-name} {comparison-operator} {timestamp-expression} | \
                            {numeric-expression}   {comparison-operator} {t0}.{numeric-column-name}  7| \
                            {string-expression}    {comparison-operator} {t0}.{string-column-name}   4| \
                            {timestamp-expression} {comparison-operator} {t0}.{timestamp-column-name} | \
                            {t0}.{numeric-column-name}   {comparison-operator} {numeric-expression}  7| \
                            {t0}.{string-column-name}    {comparison-operator} {string-expression}   4| \
                            {t0}.{timestamp-column-name} {comparison-operator} {timestamp-expression}

################################################################################
# Window functions - a.k.a. analytic functions
#
window-function-expr    ::= {window-function} OVER ({partition-or-order-by})
window-function         ::= {window-agg-func-expr} 4| COUNT(*) | RANK() | \
                            DENSE_RANK() | ROW_NUMBER()

# SUM can only take numeric argument; others can take any type;
# (AVG not actually supported here, but it should not crash)
window-agg-func-expr    ::= {non-num-arg-aggr-func}({column-expression}) 3| \
                            {num-only-aggregate-func}({numeric-expression})

# This is somewhat redundant, but since some window functions (RANK, DENSE_RANK)
# require an ORDER BY, we make that more likely; and while other window functions
# do allow this to be empty, that is less interesting, even when legal, so we
# make it less likely
partition-or-order-by   ::= [PARTITION BY {partition-by-list}]  ORDER BY {window-order-by-list} | \
                            [PARTITION BY {partition-by-list}] [ORDER BY {window-order-by-list}]
partition-by-list       ::= {column-expression} [[, {partition-by-list}]]

# Some window functions (RANK, DENSE_RANK) only allow a single int or timestamp
# expression in the ORDER BY clause, so we make those options more likely
window-order-by-list    ::= {window-order-by-item} [{asc-or-desc}] [[, {window-order-by-list}]]
window-order-by-item    ::= {column-expression} 2| {int-expression} | {timestamp-expression}

################################################################################
# Aggregate functions - used with various data types defined below
# (and in the window functions and scalar sub-queries above)
#
num-only-aggregate-func ::= SUM | AVG
num-result-aggr-func    ::= COUNT 3| APPROX_COUNT_DISTINCT
legit-non-num-aggr-func ::= MIN | MAX
non-num-aggregate-func  ::= {legit-non-num-aggr-func} 399| NONEXISTENT_AGGR_FUNC
non-num-arg-aggr-func   ::= {non-num-aggregate-func} 2| {num-result-aggr-func}
aggregate-function      ::= {non-num-arg-aggr-func}  2| {num-only-aggregate-func}

# For use with a GROUP BY clause, in a CREATE VIEW (DDL) statement, where only
# SUM, COUNT, MIN, or MAX aggregate functions are allowed
legit-non-num-aggr-f-gb ::= {non-num-aggregate-func}    2| {pg-num-result-aggr-func}
non-num-arg-aggr-func-gb::= {legit-non-num-aggr-f-gb} 798| AVG | APPROX_COUNT_DISTINCT
aggr-func-for-group-by  ::= {non-num-arg-aggr-func-gb}  3| SUM

# PostgreSQL-compatible version of the above: avoids APPROX_COUNT_DISTINCT
pg-num-result-aggr-func ::= COUNT

################################################################################
# Numeric constant values, functions, operators and expressions
#
digit-0-or-1            ::= 0 | 1
digit-0-to-4            ::= {digit-0-or-1} 2| 2 | 3 | 4
digit-0-to-5            ::= {digit-0-to-4} 5| 5
digit-0-to-7            ::= {digit-0-to-5} 6| 6 | 7
digit-0-to-8            ::= {digit-0-to-7} 8| 8
non-zero-digit          ::= 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9
digit                   ::= {non-zero-digit} 9| 0

non-negative-int-value  ::= [{non-zero-digit}[{digit}][{non-negative-int-value}]]{digit}
integer-non-null-value  ::= [-]{non-negative-int-value}
numeric-non-null-value  ::= {integer-non-null-value}.{non-negative-int-value}[{non-negative-int-value}]  3| \
                            {integer-non-null-value}[.{non-negative-int-value}[{non-negative-int-value}]] | \
                            {integer-non-null-value}.0[{non-negative-int-value}]

# Byte values as defined here run from -129 to 129; since byte is really
# defined as -127 to 127, a few of those values are illegal, which is OK
byte-start              ::= 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12
byte-non-null-value     ::= [-][{byte-start}]{digit}

byte-value              ::= {byte-non-null-value}     3| NULL
byte-rarely-null-value  ::= {byte-non-null-value}    99| NULL
integer-value           ::= {integer-non-null-value}  3| NULL
int-rarely-null-value   ::= {integer-non-null-value} 99| NULL
numeric-value           ::= {numeric-non-null-value}  3| NULL
num-rarely-null-value   ::= {numeric-non-null-value} 99| NULL

byte-expression         ::= {table-ref}.{byte-column-name} 6| {byte-column-name} 2| \
                            {byte-value} | {byte-function-expr}

int-expression          ::= {simple-integer-expr} 49| {integer-scalar-sub-q}
simple-integer-expr     ::= {table-ref}.{int-column-name} 6| {int-column-name} 2| \
                            {integer-value} | {int-function-expr} | {byte-expression}

numeric-expression      ::= {simple-numeric-expr} 49| {numeric-scalar-sub-q}
simple-numeric-expr     ::= {table-ref}.{numeric-column-name} 6| {numeric-column-name} 2| \
                            {numeric-value} | {numeric-function-expr} | {int-expression}

int-function-expr       ::= {int-expression} {math-operator} {int-expression} | \
                            {int-function-1arg}({int-expression}) | \
                            {int-function-2args}({int-expression}, {int-expression}) | \
                            {int-function-2args-1pos}({int-expression},{non-negative-int-value}) | \
                            {int-valued-string-expr} | {int-valued-time-expr} | {int-valued-t-unit-expr}
byte-function-expr      ::= {byte-expression} {math-operator} {byte-expression} | \
                            {int-function-2args}({byte-expression}, {byte-expression})
numeric-function-expr   ::= {numeric-expression} {math-operator} {numeric-expression} | \
                            {math-function-0args}[()] | \
                            {math-function-1arg}({numeric-expression}) 14| \
                            {math-function-2args}({numeric-expression}, {numeric-expression}) | \
                            {num-valued-time-expr} | {num-valued-point-expr} | {num-valued-polygon-expr}

math-operator           ::= + | - | * | /
math-function-0args     ::= PI 9| {numeric-udf-func-0args}
math-function-1arg      ::= ABS | CEILING | EXP | FLOOR | LN | LOG | LOG10 | SQRT | \
                            {numeric-udf-func-1arg} 2| SIN | COS | TAN | CSC | SEC | COT
math-function-2args     ::= POWER 9| {numeric-udf-func-2args}
int-function-2args      ::= MOD   9| {int-udf-func-2args} | BITAND | BITOR | BITXOR
int-function-1arg       ::= BITNOT
# the bit_shift functions require a positive int offset value
int-function-2args-1pos ::= BIT_SHIFT_LEFT | BIT_SHIFT_RIGHT

numeric-udf-func-0args  ::= piUdf | piUdfBoxed
byte-udf-func-1arg      ::= absTinyint | absTinyintBoxed
int-udf-func-1arg       ::= {byte-udf-func-1arg} 2| absSmallint | absSmallintBoxed | \
                            absInteger | absIntegerBoxed | absBigint | absBigintBoxed
numeric-udf-func-1arg   ::= {int-udf-func-1arg}  8| absFloat | absFloatBoxed | absDecimal
byte-udf-func-2args     ::= add2Tinyint  | add2TinyintBoxed  | add2TinyintWithoutNullCheck  | \
                            modTinyint   | modTinyintBoxed   | add2TinyintBoxedWithoutNullCheck
int-udf-func-2args      ::= {byte-udf-func-2args} 6| \
                            add2Smallint | add2SmallintBoxed | add2SmallintWithoutNullCheck | \
                            modSmallint  | modSmallintBoxed  | add2SmallintBoxedWithoutNullCheck | \
                            add2Integer  | add2IntegerBoxed  | add2IntegerWithoutNullCheck  | \
                            modInteger   | modIntegerBoxed   | add2IntegerBoxedWithoutNullCheck  | \
                            add2Bigint   | add2BigintBoxed   | add2BigintWithoutNullCheck   | \
                            modBigint    | modBigintBoxed    | add2BigintBoxedWithoutNullCheck
numeric-udf-func-2args  ::= {int-udf-func-2args} 24| \
                            add2Decimal | add2Float | add2FloatBoxed | add2FloatWithoutNullCheck | \
                            modDecimal  | modFloat  | modFloatBoxed  | add2FloatBoxedWithoutNullCheck

################################################################################
# String (VARCHAR) constant values, functions, operators and expressions
#

# Note: adding double-quote (") or backslash (\) here could cause problems for
# JSON strings; but adding other Unicode characters should be fine
character               ::= A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z | \
                            a | b | c | d | e | f | g | h | i | j | k | l | m | n | o | p | q | r | s | t | u | v | w | x | y | z | \
                            {digit} 10| . | , | ! | @ | # | $ | % | ^ | & | * | ( | ) | - | _ | + | =
characters              ::= [{character}][{character}][{character}[{characters}]]
string-non-null-value   ::= '{characters}' 4| '{str-common-pattern}[{characters}]'

# Useful for testing LIKE and STARTS WITH
str-common-pattern      ::= abc 3| ab 2| a

string-value            ::= {string-non-null-value}  3| NULL
str-rarely-null-value   ::= {string-non-null-value} 99| NULL

string-expression       ::= {simple-string-expr} 49| {string-scalar-sub-q}
simple-string-expr      ::= {table-ref}.{string-column-name} 6| {string-column-name} 2| \
                            {string-value} | {string-function-expr}
string-function-expr    ::= {string-expression} {string-operator} {string-expression} 2| \
                            {string-valued-int-expr}  4| {string-val-str-int-expr}  5| \
                            {string-val-num-int-expr} 2| {string-special-func-expr} 3| \
                            {str-valued-point-expr}    | {str-valued-polygon-expr}   | \
                            {string-function-1arg} ({string-expression}) 3| \
                            {string-function-2args}({string-expression}, {string-expression}) 2| \
                                    REGEXP_POSITION({string-expression}, {string-expression}, {case-sensitivity})   | \
                            {string-function-3args}({string-expression}, {string-expression}, {string-expression}) 2| \
                            {string-function-4args}({string-expression}, {string-expression}, {string-expression}, {string-expression})

string-operator         ::= || 9| +
string-function-1arg    ::= LOWER  3| TRIM 3| UPPER 3| {string-udf-func-1arg}
string-function-2args   ::= CONCAT 4| REGEXP_POSITION 4| {string-udf-func-2args}
string-function-3args   ::= CONCAT 4| REPLACE 4| {string-udf-func-3args}
string-function-4args   ::= CONCAT 9| {string-udf-func-4args}
# Optional third argument for the REGEXP_POSITION function
case-sensitivity        ::= 'c' | 'i' | {string-expression}

string-udf-func-1arg    ::= reverse
string-udf-func-2args   ::= concat2Varchar | add2Varchar
string-udf-func-3args   ::= concat3Varchar
string-udf-func-4args   ::= concat4Varchar

# Some functions of a string produce an integer value
int-valued-string-func  ::= CHAR_LENGTH | OCTET_LENGTH
# POSITION is a special case, due to the use of the IN keyword
int-valued-string-expr  ::= {int-valued-string-func}({string-expression}) 2| POSITION({string-expression} IN {string-expression})

# Some functions of an integer produce a string value
string-valued-int-func  ::= BIN | CHAR | HEX | SPACE
string-valued-int-expr  ::= {string-valued-int-func}({int-expression})

# Some functions of a string and an integer (or 2) produce a string value
string-val-str-int-func ::= LEFT | RIGHT | SUBSTRING
# We only allow byte values in the REPEAT function, because giving it large values can
# freeze VoltDB, consume all CPU time, and slow down your machine to a crawl; see ENG-12118
string-val-str-byte-fun ::= REPEAT
string-val-str-2int-fun ::= SUBSTRING
string-val-str-int-expr ::= {string-val-str-int-func}({string-expression}, {int-expression})  3| \
                            {string-val-str-byte-fun}({string-expression}, {byte-expression})  | \
                            {string-val-str-2int-fun}({string-expression}, {int-expression},  {int-expression})

# One function of 2 numbers (1 decimal and 1 integer) produces string values
string-val-num-int-func ::= FORMAT_CURRENCY
# One function of 1, 2, or 3 numbers (1 decimal and 2 optional integers) produces string values
string-val-num-2int-fun ::= STR
string-val-num-int-expr ::= {string-val-num-int-func}({numeric-expression}, {int-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}, {int-expression}) | \
                            {string-val-num-2int-fun}({numeric-expression}, {int-expression}, {int-expression})

# Some string functions use special keywords (e.g. PLACING, FROM, FOR)
string-special-func-expr::= OVERLAY({string-expression} PLACING {string-expression} FROM {int-expression} [FOR {int-expression}]) | \
                            SUBSTRING({string-expression} FROM {int-expression} [FOR {int-expression}]) | \
                            TRIM([[{trim-keyword} ]['{character}'] FROM ]{string-expression})
trim-keyword            ::= LEADING | TRAILING | BOTH

# Some clauses (e.g., WHERE) can include a LIKE expression; or, starting in
# V8.3, a STARTS WITH expression
string-like-expression  ::= {string-expression} LIKE {string-like-pattern} | \
                            {string-expression} STARTS WITH {str-starts-with-pattern}
string-like-pattern     ::= '{characters}%' 2| '[{characters}]%[{characters}]' 2| \
                            '%{characters}' 2| '{str-common-pattern}%' 2| \
                            {string-expression} | {string-value}
str-starts-with-pattern ::= {str-rarely-null-value} 3| '{str-common-pattern}' | \
                            {string-like-pattern}

################################################################################
# JSON (string / VARCHAR) constant values, functions, operators and expressions
#

json-object             ::= \{{json-name-value-pairs}\}
json-array              ::= \[{json-values}\]
json-name-value-pairs   ::= {json-name-value-pair}[,{json-name-value-pairs}]
json-name-value-pair    ::= "{json-name}":{json-value}
json-values             ::= {json-value}[,{json-values}]
json-value              ::= {json-string} | {json-number} | {json-object} | {json-array} | \
                            true | false | null

json-string             ::= "{json-characters}"
json-characters         ::= {json-character}[,{json-characters}]
json-character          ::= {character} | \\{json-escaped-character}
json-escaped-character  ::= " | \\ | / | b | f | n | r | t | u{four-hex-digits}

json-number             ::= {numeric-non-null-value}{json-exponent}
json-exponent           ::= {e-or-E}[{plus-or-minus}]{non-negative-int-value}
e-or-E                  ::= E 3| e
plus-or-minus           ::= - | +

# This could be anything, but it's useful to have some standard names that the
# JSON functions can refer to
json-name               ::= JN1 | JN2 | JN3 | JN4 | {characters}

json-non-null-value     ::= '{json-object}' | '{json-array}' | '{json-value}'
json-text-value         ::= {json-non-null-value}  3| NULL
json-rarely-null-value  ::= {json-non-null-value} 99| NULL

json-expression         ::= {simple-json-expr} 49| {json-scalar-sub-q}
simple-json-expr        ::= {table-ref}.{json-column-name} 6| {json-column-name} 2| \
                            {json-text-value} | {json-function-expr}
# TODO: add JSON functions:
json-function-expr      ::= {json-text-value}
json-function-1arg      ::= TODO

################################################################################
# Timestamp (date-time) constant values, functions, operators and expressions
#
month                   ::= 01 | 02 | 03 | 04 | 05 | 06 | 07 | 08 | 09 | 10 | 11 | 12
hour-more-than-12       ::= 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23
century                 ::= 18 | 19 | 20 | 21 | {digit}{digit}
year                    ::= {century}{digit}{digit}

# The "12" or "11" before the "|" makes those options more likely, making all
# valid day or hour values equally likely
day                     ::= {month} 12| {hour-more-than-12} 11| 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31
hour                    ::= {month} 12| {hour-more-than-12} 11| 00
minute-or-second        ::= {digit-0-to-5}{digit}

# PostgreSQL-compatible version of the above: avoids April 31, February 29 in non-leap year, etc.
pg-day                  ::= {month} 12| {hour-more-than-12} 11| 24 | 25 | 26 | 27 | 28

timestamp-non-null-value::= '{year}-{month}-{day} {hour}:{minute-or-second}:{minute-or-second}[.{digit}{digit}{digit}]'

timestamp-value         ::= {timestamp-non-null-value}  3| NULL
time-rarely-null-value  ::= {timestamp-non-null-value} 99| NULL

timestamp-expression    ::= {simple-timestamp-expr} 49| {timestamp-scalar-sub-q}
simple-timestamp-expr   ::= {table-ref}.{timestamp-column-name} 6| {timestamp-column-name} 2| \
                            {timestamp-value} | {timestamp-function-expr}
timestamp-function-expr ::= {timestamp-func-0args} 4| \
                            FROM_UNIXTIME({int-expression}) | \
                            TO_TIMESTAMP({short-time-unit}, {int-expression}) | \
                            TRUNCATE({dateadd-time-unit}, {timestamp-expression}) | \
                            DATEADD({dateadd-time-unit}, {int-expression}, {timestamp-expression}) | \
                            {timestamp-udf-func-expr}
timestamp-func-0args    ::= CURRENT_TIMESTAMP[()]   | NOW[()] | \
                            MIN_VALID_TIMESTAMP[()] | MAX_VALID_TIMESTAMP[()]
timestamp-udf-func-expr ::= addYearsToTimestamp({timestamp-expression}, {int-expression})

# PostgreSQL-compatible version of the above: avoids presence or absence
# of parens not supported, as well as unsupported functions
pg-timestamp-func-0args ::= CURRENT_TIMESTAMP | NOW()
pg-timest-udf-func-expr ::= {pg-timestamp-func-0args}

# One function of a timestamp produces a boolean result; as does the MIGRATING
# function, which does not take any argument, of any type (but is perhaps
# vaguely timestamp related, since it sometimes involves a TTL column)
bool-val-timestamp-expr ::= IS_VALID_TIMESTAMP({timestamp-expression}) 4| \
                            MIGRATING[()]

# Some functions of a timestamp produce an integer value
int-valued-time-func    ::= DAY | DAYOFMONTH | DAYOFWEEK | DAYOFYEAR | HOUR | MINUTE | \
                            MONTH | QUARTER | WEEK | WEEKOFYEAR | WEEKDAY | YEAR
int-valued-time-expr    ::= {int-valued-time-func}({timestamp-expression})

# One function of a timestamp produces a numeric (float) value
num-valued-time-func    ::= {int-valued-time-func} 3| SECOND
num-valued-time-expr    ::= {num-valued-time-func}({timestamp-expression})

# Some functions of a time-unit (string) and a timestamp produce an integer value
# (and EXTRACT optionally uses the special keyword FROM)
# Note: EXTRACT actually produces a decimal (not integer) when the SECOND time-unit is used,
# which may produce an error in some contexts, if an integer is expected - which is OK
int-valued-t-unit-expr  ::= SINCE_EPOCH({short-time-unit}, {timestamp-expression}) | \
                            EXTRACT({extract-time-unit}, {timestamp-expression}) | \
                            EXTRACT({extract-time-unit} FROM {timestamp-expression})

# Time units used in the definitions above:
long-time-unit          ::= YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE | SECOND
short-time-unit         ::= SECOND | MILLISECOND | MILLIS | MICROSECOND | MICROS
special-time-unit       ::= DAY_OF_MONTH | DAY_OF_WEEK | DAY_OF_YEAR | WEEK | WEEK_OF_YEAR | WEEKDAY
extract-time-unit       ::= {long-time-unit} | {special-time-unit}
dateadd-time-unit       ::= {long-time-unit} | {short-time-unit}

################################################################################
# Varbinary (binary) constant values, functions, operators and expressions
#
hex-alphabetic-digit    ::= A | B | C | D | E | F | a | b | c | d | e | f
hex-digit               ::= {digit} 2| {hex-alphabetic-digit}
max4-hex-digits         ::= [[[{hex-digit}]{hex-digit}]{hex-digit}]{hex-digit}
four-hex-digits         ::= {hex-digit}{hex-digit}{hex-digit}{hex-digit}
eight-hex-digits        ::= {four-hex-digits}{four-hex-digits}
thirty-two-hex-digits   ::= {eight-hex-digits}{eight-hex-digits}{eight-hex-digits}{eight-hex-digits}
even-num-of-hex-digits  ::= {hex-digit}{hex-digit}[{even-num-of-hex-digits}]
varbinary-non-null-value::= x'{even-num-of-hex-digits}'

varbinary-value         ::= {varbinary-non-null-value}  3| NULL
varbin-rarely-null-value::= {varbinary-non-null-value} 99| NULL

varbinary-expression    ::= {simple-varbinary-expr} 49| {varbinary-scalar-sub-q}
simple-varbinary-expr   ::= {table-ref}.{varbinary-column-name} 6| {varbinary-column-name} 2| \
                            {varbinary-value} | {varbinary-function-expr}

varbinary-function-expr ::= {varbinary-udf-func-expr}
varbinary-udf-func-2args::= add2Varbinary | add2VarbinaryBoxed | btrim | btrimBoxed
varbinary-udf-func-expr ::= {varbinary-udf-func-2args}({varbinary-expression}, {varbinary-expression})

# Some functions of a varbinary produce a string value
string-valued-varb-func ::= BIN | CHAR | HEX | SPACE
string-valued-varb-expr ::= {string-valued-int-func}({int-expression})


################################################################################
# Special Internet address varbinary and string values, functions, operators
# and expressions used with the functions:
# INET6_ATON, INET6_NTOA, INET_ATON, INET_NTOA
# (If we called these functions on regular varbinary and string values, they
# would simply always give an error message, which would not test much.)
#

zero-to-255             ::= 25{digit-0-to-5} | 2{digit-0-to-4}{digit} 5| 1{digit}{digit} 10| \
                            {non-zero-digit}{digit} 9| {digit}

# Note: "-nnull-value" is short for "-non-null-value"
varbin-ipv4-nnull-value ::= x'{eight-hex-digits}'
varbin-ipv6-nnull-value ::= x'{thirty-two-hex-digits}'
string-ipv4-nnull-value ::= '{zero-to-255}.{zero-to-255}.{zero-to-255}.{zero-to-255}'
string-ipv6-nnull-value ::= '{max4-hex-digits}:[{max4-hex-digits}:[{max4-hex-digits}:[{max4-hex-digits}:{max4-hex-digits}]:{max4-hex-digits}]:{max4-hex-digits}]:{max4-hex-digits}' 2|  \
                            ':[{max4-hex-digits}:[{max4-hex-digits}:[{max4-hex-digits}:{max4-hex-digits}]:{max4-hex-digits}]:{max4-hex-digits}]:{max4-hex-digits}' | \
                            '{max4-hex-digits}:[{max4-hex-digits}:[{max4-hex-digits}:[{max4-hex-digits}:{max4-hex-digits}]:{max4-hex-digits}]:{max4-hex-digits}]:'

varbin-ipv4-value       ::= {varbin-ipv4-nnull-value}  3| NULL
varbin-ipv6-value       ::= {varbin-ipv6-nnull-value}  3| NULL
string-ipv4-value       ::= {string-ipv4-nnull-value}  3| NULL
string-ipv6-value       ::= {string-ipv6-nnull-value}  3| NULL

# Note: "-rnull-value" is short for "-rarely-null-value"
varbin-ipv4-rnull-value ::= {varbin-ipv4-nnull-value} 99| NULL
varbin-ipv6-rnull-value ::= {varbin-ipv6-nnull-value} 99| NULL
string-ipv4-rnull-value ::= {string-ipv4-nnull-value} 99| NULL
string-ipv6-rnull-value ::= {string-ipv6-nnull-value} 99| NULL

varbin-ipv4-expression  ::= {table-ref}.{varbin-ipv4-column-name} 6| {varbin-ipv4-column-name} 2| \
                            {varbin-ipv4-value} | {varbin-ipv4-func-expr}
varbin-ipv6-expression  ::= {table-ref}.{varbin-ipv6-column-name} 6| {varbin-ipv6-column-name} 2| \
                            {varbin-ipv6-value} | {varbin-ipv6-func-expr}
varbin-ipv4-func-expr   ::= INET_ATON({string-ipv4-expression})
varbin-ipv6-func-expr   ::= INET6_ATON({string-ipv6-expression})

string-ipv4-expression  ::= {table-ref}.{string-ipv4-column-name} 6| {string-ipv4-column-name} 2| \
                            {string-ipv4-value} | {string-ipv4-func-expr}
string-ipv6-expression  ::= {table-ref}.{string-ipv6-column-name} 6| {string-ipv6-column-name} 2| \
                            {string-ipv6-value} | {string-ipv6-func-expr}
string-ipv4-func-expr   ::= INET_NTOA({varbin-ipv4-expression})
string-ipv6-func-expr   ::= INET6_NTOA({varbin-ipv6-expression})

################################################################################
# Geospatial Point constant values, functions, operators and expressions
#

number-less-than-80     ::= {digit-0-to-7}[{digit}][.{non-negative-int-value}]
number-less-than-90     ::= {digit-0-to-8}[{digit}][.{non-negative-int-value}]
number-less-than-100    ::= {digit}[{digit}][.{non-negative-int-value}]

# Latitude is a number between -100 and 100 (exclusive); longitude is between
# -200 and 200 (exclusive); these include some illegal values, which is OK
latitude                ::= [-]{number-less-than-100}
longitude               ::= [-][1]{number-less-than-100}
point-non-null-value    ::= PointFromText('POINT({longitude} {latitude})')

# PostgreSQL-compatible version of the above: avoids differing treatment of illegal values:
#   latitude is a number between -90 and 90 (exclusive);
#   longitude is a number between -180 and 180 (exclusive);
# illegal values not allowed, since they cause inconsistencies with PostgreSQL
pg-latitude             ::= [-]{number-less-than-90}
pg-longitude            ::= [-][1]{number-less-than-80}

point-value             ::= {point-non-null-value}  3| NULL
point-rarely-null-value ::= {point-non-null-value} 99| NULL

point-expression        ::= {simple-point-expr} 49| {point-scalar-sub-q}
simple-point-expr       ::= {table-ref}.{point-column-name} 6| {point-column-name} 2| \
                            {point-value} | {point-function-expr}
point-function-expr     ::= {simple-point-func-expr} 4| {point-udf-func-expr}
simple-point-func-expr  ::= CENTROID({polygon-expression}) | {point-non-null-value}
point-udf-func-expr     ::= add2GeographyPoint({point-expression}, {point-expression})

# Some functions of a point produce a string or numeric value
str-valued-point-expr   ::= AsText({point-expression})
num-valued-point-expr   ::= LATITUDE({point-expression}) | LONGITUDE({point-expression})

################################################################################
# Geospatial Polygon constant values, functions, operators and expressions
#

# About a quarter of these simple polygons will be defined clockwise, hence invalid
polygon-non-null-value  ::= {polygon-from-text}('POLYGON((0 0, {longitude} 0, 0 {latitude}, 0 0))') | \
                            {polygon-from-text}('POLYGON((-2 -2, 10 -2, -2 10, -2 -2),(-1 -1, -1 {digit}, {digit} -1, -1 -1))')
polygon-from-text       ::= PolygonFromText 3| ValidPolygonFromText

polygon-value           ::= {polygon-non-null-value}  3| NULL
poly-rarely-null-value  ::= {polygon-non-null-value} 99| NULL

# UDF TODO: add back something like this (here and elsewhere):
#polygon-expression      ::= {non-num-aggregate-func}({polygon-expression}) 9| ...

polygon-expression      ::= {simple-polygon-expr} 49| {polygon-scalar-sub-q}
simple-polygon-expr     ::= {table-ref}.{polygon-column-name} 6| {polygon-column-name} 2| \
                            {polygon-value} | {polygon-function-expr}
polygon-function-expr   ::= {simple-polygon-func-expr} 4| {polygon-udf-func-expr}
simple-polygon-func-expr::= {polygon-non-null-value}
polygon-udf-func-expr   ::= addGeographyPointToGeography({polygon-expression}, {point-expression})

# Some functions of a polygon produce a string or numeric value
str-valued-polygon-expr ::= AsText({polygon-expression}) | IsInvalidReason({polygon-expression})
int-valued-polygon-expr ::= NumPoints({polygon-expression}) | NumInteriorRings({polygon-expression})
num-valued-polygon-expr ::= {int-valued-polygon-expr} 2| {distance-function} 3| \
                            AREA({polygon-expression}) | {int-valued-polygon-udf}
distance-function       ::= DISTANCE({point-expression},   {point-expression})   3| \
                            DISTANCE({point-expression},   {polygon-expression}) 3| \
                            DISTANCE({polygon-expression}, {point-expression})   3| \
                            DISTANCE({polygon-expression}, {polygon-expression})
int-valued-polygon-udf  ::= NumRings({polygon-expression}) | NumPointsUdf({polygon-expression})

# Some functions of a polygon produce a boolean result
bool-valued-polygon-expr::= IsValid({polygon-expression}) | {dwithin-function} 2| \
                            CONTAINS({polygon-expression}, {point-expression})
dwithin-function        ::= DWITHIN({point-expression},   {point-expression},   {numeric-expression}) 3| \
                            DWITHIN({point-expression},   {polygon-expression}, {numeric-expression}) 3| \
                            DWITHIN({polygon-expression}, {point-expression},   {numeric-expression}) 3| \
                            DWITHIN({polygon-expression}, {polygon-expression}, {numeric-expression})

################################################################################
# Non-geospatial (ng-) alternative values of some of the above definitions, for
# use with SQLCoverage, to avoid issues with Geospatial types (point & polygon,
# i.e. GEOGRAPHY_POINT & GEOGRAPHY); these definitions are largely the same,
# but with the points and polygons [and varbinary?] left out, or NULL
#
# Note: this section is not currently used, though it may be used in the future,
# in a version that feeds queries to SQLCoverage (see ENG-10240); though more
# likely it will be replaced by the various 'pg-...' definitions above.

ng-non-int-str-column-name ::= {timestamp-column-name} | {varbinary-column-name} | {int-column-name}

ng-random-type-value       ::= {integer-value} | {numeric-value} | {string-value} | {timestamp-value} | \
                               {varbinary-value}
ng-in-or-up-sert-values    ::= {insert-values-id-num}    | {insert-values-id-str}   | {insert-values-id-time} | \
                               {insert-values-id-varbin} | \
                               {insert-values-multiple}  | {insert-values-all}      | {insert-values-backward}
ng-in-or-up-sert-select    ::= {insert-select-id-num}    | {insert-select-id-str}   | {insert-select-id-time} | \
                               {insert-select-id-varbin} | \
                               {insert-select-multiple}  | {insert-select-all}      | {insert-select-backward}
ng-insert-values-multiple  ::= SERT INTO {table-name} (ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                               {varbinary-column-name} ) VALUES ({integer-non-null-value}, \
                               {numeric-value}, {string-value}, {timestamp-value}, {varbinary-value} )
ng-insert-values-all       ::= SERT INTO {table-name} ( \
                               ID, TINY, SMALL, INT1, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME1, VARBIN \
                               ) VALUES ( {integer-non-null-value}, {byte-value}, {integer-value}, {integer-value}, {integer-value}, \
                               {numeric-value}, {numeric-value}, {string-value}, {string-value}, {string-value}, {timestamp-value}, \
                               {varbinary-value} )
ng-insert-values-backward  ::= SERT INTO {table-name} ( \
                               VARBIN, TIME1, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT1, SMALL, TINY, ID \
                               ) VALUES ( {varbinary-value}, {timestamp-value}, {string-value}, \
                               {string-value}, {string-value}, {numeric-value}, {numeric-value}, {integer-value}, {integer-value}, \
                               {integer-value}, {byte-value}, {integer-non-null-value} )
ng-insert-select-multiple  ::= SERT INTO {table-name} ( ID, {numeric-column-name}, {string-column-name}, {timestamp-column-name}, \
                               {varbinary-column-name} ) SELECT {int-column-name}, \
                               {numeric-column-name}, {string-column-name}, {timestamp-column-name}, {varbinary-column-name} \
                               FROM {table-ref}
ng-insert-select-all       ::= SERT INTO {table-name} ( \
                               ID, TINY, SMALL, INT1, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME1, VARBIN ) SELECT \
                               ID, TINY, SMALL, INT1, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME1, VARBIN FROM {table-ref}
ng-insert-select-backward  ::= SERT INTO {table-name} ( \
                               VARBIN, TIME1, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT1, SMALL, TINY, ID ) SELECT \
                               VARBIN, TIME1, VCHAR_INLINE, VCHAR_INLINE_MAX, VCHAR, DEC, NUM, BIG, INT1, SMALL, TINY, ID FROM {table-ref}
ng-star                    ::= ID, TINY, SMALL, INT1, BIG, NUM, DEC, VCHAR, VCHAR_INLINE_MAX, VCHAR_INLINE, TIME1, VARBIN
ng-point-value             ::= NULL
ng-polygon-value           ::= NULL


################################################################################
################################################################################
################################################################################
#
# DDL statements
#
# TODO: we probably should eventually combine the sql-ddl-grammar.txt file with
# this one (i.e., copy it to here), but what follows are the only sections that
# we need so far (formerly in that file but moved here, with modifications).

################################################################################
# Grammar rules for all DDL statements:
#
# TODO: include all DDL statements (with non-zero weights), once implemented,
# especially CREATE TABLE, ALTER TABLE, and PARTITION statements
#
ddl-statement           ::= {create-statement}      | {alter-table-statement} 0| \
                            {partition-table-stmnt} | {drop-statement}

create-statement        ::= {create-non-table-stmnt} 3| {create-table-statement}

create-non-table-stmnt  ::= {create-view-statement} | {create-index-statement} | \
                            {create-proc-statement}

################################################################################
# Names for tables, views, indexes, and stored procedures, to be used in DDL
# statements: some, listed elsewhere, use a fixed schema; others, listed here,
# may be changed via DDL:
#
ddl-table-name          ::= DT{digit-0-or-1}{digit}
ddl-view-name           ::= DV{digit-0-or-1}{digit}
ddl-index-name          ::= DIDX{digit-0-or-1}{digit}
ddl-proc-name           ::= {random-proc-0params}

################################################################################
# Grammar rules for CREATE TABLE statements:
################################################################################
#
# TODO: flesh this out more: not just for MIGRATE and TTL (see ENG-15795)
#
create-table-statement  ::= {create-simple-table} 2| {create-migrating-table} | \
                            {drop-create-part-table} 999| {create-table-statement}

create-simple-table     ::= CREATE TABLE {ddl-table-name:tn} \
                            [{migrate-to-target}] \
                            ({create-table-column-list}) \
                            [{ttl-definition}]

create-migrating-table  ::= CREATE TABLE {ddl-table-name:tn} \
                            {migrate-to-target} \
                            ({create-table-column-list}) \
                            [{ttl-definition}][; \
                            {create-non-migrating-idx}]

drop-create-part-table  ::= [DROP TABLE {ddl-table-name:tn} IF EXISTS CASCADE;] \
                            {create-simple-table}[; \
                            {partition-table-stmnt}][; \
                            {create-index-statement}]

migrate-to-target       ::= MIGRATE TO TARGET grammartarget
ttl-definition          ::= USING TTL {ttl-value} [{ttl-time-unit}] \
                            ON COLUMN {ttl-column:ttl} \
                            [{batch-size}][ {max-frequency}]
ttl-value               ::= {non-negative-int-value}
ttl-time-unit           ::= SECONDS 5| MINUTES 3| HOURS | DAYS
ttl-column              ::= {int-non-small-col-name} 2| {timestamp-column-name}
batch-size              ::= BATCH_SIZE {non-negative-int-value}[{digit}[{digit}]]
max-frequency           ::= MAX_FREQUENCY {non-negative-int-value}

create-table-column-list::= {standard-column-list} 3| {varied-column-list}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
standard-column-list    ::= \
  ID      INTEGER  {probable-primary-key},   \
  TINY    TINYINT  {column-byte-attributes}, \
  SMALL   SMALLINT {column-num-attributes},  \
  INT1     INTEGER  {probable-not-null-num},  \
  BIG     BIGINT   {probable-not-null-num},  \
  NUM     FLOAT    {column-num-attributes},  \
  DEC     DECIMAL  {column-num-attributes},  \
  VCHAR_INLINE      VARCHAR(14)       {probable-not-null-str}, \
  VCHAR_INLINE_MAX  VARCHAR(63 BYTES) {probable-not-null-str}, \
  VCHAR_OUTLINE_MIN VARCHAR(64 BYTES) {probable-not-null-str}, \
  VCHAR             VARCHAR           {probable-not-null-str}, \
  VCHAR_JSON        VARCHAR(1000)     {column-json-attributes}, \
  TIME1    TIMESTAMP       {probable-not-null-time}, \
  VARBIN  VARBINARY(100)  {probable-not-null-varb}, \
  POINT   GEOGRAPHY_POINT {column-null-attributes}, \
  POLYGON GEOGRAPHY       {column-null-attributes}, \
  IPV4    VARCHAR(15)     {column-null-attributes}, \
  IPV6    VARCHAR(60)     {column-null-attributes}, \
  VBIPV4  VARBINARY(4)    {column-null-attributes}, \
  VBIPV6  VARBINARY(16)   {column-null-attributes}

# Note: if you add a new column to the DDL file, add it here
# (and in other places with this comment)
varied-column-list      ::= \
     ID      INTEGER  {probable-primary-key}     \
[[,  TINY    TINYINT  {column-byte-attributes}]] \
[[,  SMALL   SMALLINT {column-num-attributes}]]  \
[ ,  INT1     INTEGER  {probable-not-null-num}]   \
[ ,  BIG     BIGINT   {probable-not-null-num}]   \
[[,  NUM     FLOAT    {column-num-attributes}]]  \
[[,  DEC     DECIMAL  {column-num-attributes}]]  \
[[,  VCHAR_INLINE      VARCHAR(14)       {probable-not-null-str}]]  \
[[,  VCHAR_INLINE_MAX  VARCHAR(63 BYTES) {probable-not-null-str}]]  \
[[,  VCHAR_OUTLINE_MIN VARCHAR(64 BYTES) {probable-not-null-str}]]  \
[[,  VCHAR             VARCHAR           {probable-not-null-str}]]  \
[[,  VCHAR_JSON        VARCHAR(1000)     {column-json-attributes}]] \
[ ,  TIME1    TIMESTAMP       {probable-not-null-time}]  \
[[,  VARBIN  VARBINARY(100)  {probable-not-null-varb}]] \
[[,  POINT   GEOGRAPHY_POINT {column-null-attributes}]] \
[[,  POLYGON GEOGRAPHY       {column-null-attributes}]] \
[[,  IPV4    VARCHAR(15)     {column-null-attributes}]] \
[[,  IPV6    VARCHAR(60)     {column-null-attributes}]] \
[[,  VBIPV4  VARBINARY(4)    {column-null-attributes}]] \
[[,  VBIPV6  VARBINARY(16)   {column-null-attributes}]]

# TODO: work this out better??:
probable-primary-key    ::= {not-null-primary-key} 18| {not-null} | {column-num-attributes}
probable-not-null-num   ::= {not-null} 9| {column-num-attributes}
probable-not-null-str   ::= {not-null} 9| {column-str-attributes}
probable-not-null-time  ::= {not-null} 9| {column-time-attributes}
probable-not-null-varb  ::= {not-null} 9| {column-varb-attributes}
not-null-maybe-pk       ::= {not-null} 9| {not-null-primary-key:mpk}
not-null-primary-key    ::= {not-null} {primary-key}{empty:mpk}
not-null                ::= NOT NULL
primary-key             ::= PRIMARY KEY

column-byte-attributes  ::= [{default-byte}     ][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-num-attributes   ::= [{default-numeric}  ][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-str-attributes   ::= [{default-string}   ][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-json-attributes  ::= [{default-json}     ][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-time-attributes  ::= [{default-timestamp}][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-varb-attributes  ::= [{default-varbinary}][[ {not-null-maybe-pk}]][ {unique-or-assume-unique:uau}]
column-null-attributes  ::= [{default-null}     ][[ {not-null-maybe-pk}]]  {empty}

default-byte            ::= DEFAULT {byte-value}      | DEFAULT 0
default-numeric         ::= DEFAULT {numeric-value}   | DEFAULT 0
default-string          ::= DEFAULT {string-value}    | DEFAULT '0'
default-json            ::= DEFAULT {json-text-value} | DEFAULT '\{\}'
default-timestamp       ::= DEFAULT {timestamp-value} | DEFAULT '2018-10-28 23:14:59'
default-varbinary       ::= DEFAULT {varbinary-value} | DEFAULT x'00'
# GEOGRAPHY_POINT and GEOGRAPHY columns cannot have a non-null default;
# and we don't bother to set one for the 'internet' (IPV) columns
default-null            ::= DEFAULT NULL

################################################################################
# Grammar rules for CREATE VIEW statements:
################################################################################
#
create-view-statement   ::= CREATE VIEW {ddl-view-name} ({create-view-column-list;cvcl}) AS \
                            {simple-groupby-select}

################################################################################
# Grammar rules for a CREATE INDEX statement:
# indexes may be created on any table or view, not only on the 'ddl-...' ones
# defined above.
################################################################################
#
create-index-statement  ::= {create-simple-index} 3| {create-non-migrating-idx}

create-index-clause     ::= CREATE[ {unique-or-assume-unique}] INDEX {ddl-index-name} \
                            ON {ddl-table-name:tn} ({column-expression-list}) \

unique-or-assume-unique ::= UNIQUE | ASSUMEUNIQUE

create-simple-index     ::= {create-index-clause} [{where-clause}]

create-non-migrating-idx::= {create-index-clause} {where-not-migrating}

################################################################################
# Grammar rules for CREATE / DROP PROCEDURE statements:
# stored procedures may be created on any table or view, not only on the
# 'ddl-...' ones defined above.
################################################################################
#
create-proc-statement   ::= {create-proc-as-statement} 2| {drop-create-proc-stmnt}

# This version drops a procedure first (if it exists), before creating a new
# one using the same procedure name, so this is more likely to be valid
drop-create-proc-stmnt  ::= DROP PROCEDURE {ddl-proc-name:p0} IF EXISTS; \
                            {create-proc-as-statement}

################################################################################
# Grammar rules for a CREATE PROCEDURE AS statement:
################################################################################
#
# TODO: eventually uncomment the ALLOW {role-name-list} clause (after defining
# role-name-list, and dealing with roles generally)
create-proc-as-statement::= CREATE PROCEDURE {ddl-proc-name:p0} \
                            [PARTITION ON TABLE {table-name-ref} \
                              COLUMN {column-name}[ PARAMETER {digit}]] \
#                           [[[ALLOW {role-name-list}]]] \
                            AS {sql-statement}

################################################################################
# Grammar rules for a PARTITION TABLE  statement:
################################################################################
#
partition-table-stmnt   ::= PARTITION TABLE {ddl-table-name:tn} ON COLUMN {partition-column}

partition-column        ::= {int-non-small-col-name} 8| {string-column-name} 8| \
                            {varbinary-column-name}  3| {any-column-name}

################################################################################
# Grammar rules for all DROP statements, i.e., DROP TABLE, DROP VIEW,
# DROP INDEX, and DROP PROCEDURE statements:
################################################################################
#
drop-statement          ::= {drop-table-statement} | {drop-view-statement} | \
                            {drop-index-statement} | {drop-proc-statement}
drop-table-statement    ::= DROP TABLE     {ddl-table-name}[[ IF EXISTS]][[ CASCADE]]
drop-view-statement     ::= DROP VIEW      {ddl-view-name}[   IF EXISTS]
drop-index-statement    ::= DROP INDEX     {ddl-index-name}[  IF EXISTS]
drop-proc-statement     ::= DROP PROCEDURE {ddl-proc-name}[   IF EXISTS]
